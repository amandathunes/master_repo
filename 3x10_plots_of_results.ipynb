{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#FF9671\"> <b> Results and Analysis of the concatenated plots for each model </b> </span>\n",
    "\n",
    "<span style=\"color:#D65DB1\"> <b> Plot 1 </b> </span> : Plot boxplot of the target lengdt default for each global score.\n",
    "    \n",
    "    1. For the 3 experiments for each model\n",
    "    What model had better results when it comes to plotting?\n",
    "\n",
    "-> Plot over the how many word over and under the target word length was.\n",
    "    \n",
    "    1. For the 3 experiments for each model\n",
    "    What model had better results when it comes to plotting?\n",
    "\n",
    "Plot 2 -> \n",
    "\n",
    "<span style=\"color:#F9F871\"> F9F871 </span>\n",
    "<span style=\"color:#FFC75F\"> FFC75F </span>\n",
    "<span style=\"color:#FF9671\"> FF9671 </span>\n",
    "\n",
    "<span style=\"color:#FF6F91\"> FF6F91 </span>\n",
    "<span style=\"color:#D65DB1\"> D65DB1 </span>\n",
    "<span style=\"color:#845EC2\"> 845EC2 </span>\n",
    "\n",
    "<span style=\"color:#00C0FF\">#00C0FF </span>\n",
    "<span style=\"color:#00D5F7\">#00D5F7 </span>\n",
    "<span style=\"color:#00E6DB\">#00E6DB </span>\n",
    "\n",
    "<span style=\"color:#58F2B3\">#58F2B3 </span>\n",
    "<span style=\"color:#ADF88B\">#ADF88B </span>\n",
    "<span style=\"color:#F9F871\">#F9F871 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#58F2B3\"> Library Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 19:31:05.586396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-05 19:31:06.759154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tiny__concatenated_audio_information_scores_id_sorted_v1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiny__concatenated_audio_information_scores_id_sorted_v1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m model_name \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m scores_id_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tiny__concatenated_audio_information_scores_id_sorted_v1.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import self_made_functions as smf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_name = 'tiny__concatenated_audio_information_scores_id_sorted_v1.csv'\n",
    "model_name = file_name.split('__')[0]\n",
    "\n",
    "scores_id_sorted = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Whisper model tiny, is the deviation in extra words transcribed big for the lower score, and it gets smaller for higher score, but then the outliers are way bigger than at the lower scores.\n",
    "\n",
    "See: \n",
    "* Audio clip: 22 -> 210_220: Transcribed a longer sentence than the target sentence.\n",
    "* Audio clip: 20 -> It has 23 unique transcriptions whit no extra words.\n",
    "\n",
    "\n",
    "<span style=\"color:#FF6F91\"> **Test categories:**\n",
    "\n",
    "1. <span style=\"color:#FF9671\"> Grouping by score, sorted IDs : <code> {model_name}__concatenated_audio_information_scores_id_sorted </code></span>\n",
    "2. <span style=\"color:#FFC75F\"> Grouping by score, mixed IDs  : <code> {model_name}__concatenated_audio_information_scores_id_mixed </code></span>\n",
    "\n",
    "<!-- 3. <span style=\"color:#F9F871\"> Grouping by IDs: sorted scores: <code> {model_name}__concatenated_audio_information_by_id</code> </span> -->\n",
    "3. <span style=\"color:#F9F871\"> Grouping by IDs: sorted scores: <code> {model_name}__concatenated_audio_information_group_id_sorted_score</code> </span>\n",
    "4. <span style=\"color:#FF6F91\"> Random shuffling: no group    : <code> {model_name}__concatenated_audio_information_no_group_mixed </code></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['tiny', 'nb-whisper-tiny', 'nb-whisper-tiny-verbatim',\n",
    "        'base', 'nb-whisper-base', 'nb-whisper-base-verbatim',\n",
    "        'medium', 'nb-whisper-medium', 'nb-whisper-medium-verbatim']\n",
    "\n",
    "different_tests = [\n",
    "'__concatenated_audio_information_scores_id_sorted', # 1\n",
    "'__concatenated_audio_information_scores_id_mixed', # 2\n",
    "# '__concatenated_audio_information_by_id', # 3\n",
    "'__concatenated_audio_information_group_id_sorted_score', # 3\n",
    "'__concatenated_audio_information_no_group_mixed'] # 4\n",
    "\n",
    "test_names = ['Grouped by score, sorted IDs', \n",
    "        'Grouped by score, mixed IDs',\n",
    "        'Grouped by ID: sorted scores',\n",
    "        'No groups, mixed data']\n",
    "\n",
    "info_dir ='./3x10_Concatenation_information'\n",
    "\n",
    "figure_dir = './Concat_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: scores_id_sorted\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(different_tests):\n",
    "    # Get the name of the current test\n",
    "    current_test = test.split('information_')[1]\n",
    "    \n",
    "    # --- Define and create the directory to save the plots --- #\n",
    "    name = f'Test {idx+1}: {current_test}'\n",
    "    save_dir = os.path.join(figure_dir, name)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f'Created directory: {save_dir}')\n",
    "    print(name)\n",
    "    \n",
    "    # --- Get the list of file names for the current test --- #\n",
    "    test_lst = os.listdir(info_dir)\n",
    "    this_test_list = [file for file in test_lst if file.endswith(f'{current_test}_v1.csv')]\n",
    "    if len(this_test_list) != 9: # The list is wrong if this is triggered\n",
    "        print(f'Error: {len(this_test_list)} files found for {current_test}')\n",
    "        break\n",
    "    \n",
    "    # --- Create a big data frame and concatenate all the data --- #\n",
    "    the_chad_df = pd.DataFrame()\n",
    "    \n",
    "    for data in this_test_list:\n",
    "        data_path = os.path.join(info_dir, data)\n",
    "        beta_df = pd.read_csv(data_path)\n",
    "        model_name = data.split('__')[0] \n",
    "        \n",
    "        # --- Extract and modify the model name for plotting --- # \n",
    "        if model_name.startswith('nb'):\n",
    "            mn_split = model_name.split('-whisper')\n",
    "            if not len(mn_split) == 2:\n",
    "                print(f'Error: model name split failed. Len: {len(mn_split)}. Split: {mn_split}')\n",
    "            else:\n",
    "                model_name = 'NNL' + mn_split[1]\n",
    "        else:\n",
    "            model_name = model_name.capitalize()\n",
    "            \n",
    "        beta_df['model_name'] = model_name\n",
    "        beta_df = beta_df.drop(columns=['translated_CER','translated_WER', 'target_CER', 'target_CER_sum'])\n",
    "        beta_df = beta_df.rename(columns={'trans_CER':'translated_CER', 'trans_WER':'translated_WER', 'score':'global_score'})\n",
    "        beta_df['translated_CER'] = beta_df['input_string'].apply(lambda x: x.split(' ').count()\n",
    "        \n",
    "        reorder_column = [\"global_score\", \n",
    "                        'input_string', 'translated_string',\n",
    "                        'target_WER', \n",
    "                        'translated_CER', 'translated_WER', 'model_name',                         \n",
    "                        \n",
    "                        \"target_word\", \"PER\", \n",
    "                        \"transcribed_word\", \"CER\", \n",
    "                        \"transcribed_word_striped\", \"striped_CER\",\n",
    "                        \"file_name\", \"model_name\"]\n",
    "        \n",
    "        beta_df = beta_df[reorder_column]\n",
    "        print(len(beta_df.columns.values))\n",
    "        \n",
    "        # --- Concatenate the data --- #\n",
    "        the_chad_df = pd.concat([the_chad_df, beta_df], axis=0)\n",
    "    \n",
    "    \n",
    "    # for model in models:\n",
    "        \n",
    "    #     file_name = model + test + '_v1.csv'\n",
    "    #     scores_id_sorted = pd.read_csv(file_name)\n",
    "    #     smf.plot_concatenation_information(scores_id_sorted, model, save_dir)\n",
    "    # # for model in models:\n",
    "    # #     file_name = model + test + '_v1.csv'\n",
    "    # #     scores_id_sorted = pd.read_csv(file_name)\n",
    "    break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>input_string</th>\n",
       "      <th>translated_string</th>\n",
       "      <th>target_CER</th>\n",
       "      <th>target_CER_sum</th>\n",
       "      <th>target_WER</th>\n",
       "      <th>unique_id's</th>\n",
       "      <th>speaker_id's</th>\n",
       "      <th>length_deviation_words</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>translated_CER</th>\n",
       "      <th>translated_WER</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>øre sjakk rød planke ødelagt glorie krakk blå ...</td>\n",
       "      <td>fly flakt roe</td>\n",
       "      <td>[0.3333333333333333, 0.0, 0.0, 0.3333333333333...</td>\n",
       "      <td>3.028571</td>\n",
       "      <td>0.7</td>\n",
       "      <td>['d19', 'd16', 'd17', 'd11', 'd13', 'd09']</td>\n",
       "      <td>['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...</td>\n",
       "      <td>-7</td>\n",
       "      <td>words_0_10.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_1_sorted</td>\n",
       "      <td>0.8596491228070176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNL-medium-verbatim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                       input_string translated_string  \\\n",
       "0      1  øre sjakk rød planke ødelagt glorie krakk blå ...     fly flakt roe   \n",
       "\n",
       "                                          target_CER  target_CER_sum  \\\n",
       "0  [0.3333333333333333, 0.0, 0.0, 0.3333333333333...        3.028571   \n",
       "\n",
       "   target_WER                                 unique_id's  \\\n",
       "0         0.7  ['d19', 'd16', 'd17', 'd11', 'd13', 'd09']   \n",
       "\n",
       "                                        speaker_id's  length_deviation_words  \\\n",
       "0  ['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...                      -7   \n",
       "\n",
       "       audio_name                                  audio_path  \\\n",
       "0  words_0_10.wav  ../3x10_Concatenations/3x10_score_1_sorted   \n",
       "\n",
       "       translated_CER  translated_WER           model_name  \n",
       "0  0.8596491228070176             1.0  NNL-medium-verbatim  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the_chad_df[the_chad_df['translated_CER']]\n",
    "# the_chad_df['translated_CER'][0]\n",
    "# Want to know where the the_chad_df['translated_CER'] is not NaN\n",
    "the_chad_df['trans_WER'].notnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
