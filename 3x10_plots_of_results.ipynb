{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#FF9671\"> <b> Results and Analysis of the concatenated plots for each model </b> </span>\n",
    "\n",
    "<span style=\"color:#D65DB1\"> <b> Plot 1 </b> </span> : Plot boxplot of the target lengdt default for each global score.\n",
    "    \n",
    "    1. For the 3 experiments for each model\n",
    "    What model had better results when it comes to plotting?\n",
    "\n",
    "-> Plot over the how many word over and under the target word length was.\n",
    "    \n",
    "    1. For the 3 experiments for each model\n",
    "    What model had better results when it comes to plotting?\n",
    "\n",
    "Plot 2 -> \n",
    "\n",
    "<span style=\"color:#F9F871\"> F9F871 </span>\n",
    "<span style=\"color:#FFC75F\"> FFC75F </span>\n",
    "<span style=\"color:#FF9671\"> FF9671 </span>\n",
    "\n",
    "<span style=\"color:#FF6F91\"> FF6F91 </span>\n",
    "<span style=\"color:#D65DB1\"> D65DB1 </span>\n",
    "<span style=\"color:#845EC2\"> 845EC2 </span>\n",
    "\n",
    "<span style=\"color:#00C0FF\">#00C0FF </span>\n",
    "<span style=\"color:#00D5F7\">#00D5F7 </span>\n",
    "<span style=\"color:#00E6DB\">#00E6DB </span>\n",
    "\n",
    "<span style=\"color:#58F2B3\">#58F2B3 </span>\n",
    "<span style=\"color:#ADF88B\">#ADF88B </span>\n",
    "<span style=\"color:#F9F871\">#F9F871 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#58F2B3\"> Library Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import self_made_functions as smf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_name = './3x10_Concatenation_information/first_wrong_transcriptions/tiny__concatenated_audio_information_scores_id_sorted_v1.csv'\n",
    "model_name = file_name.split('__')[0]\n",
    "scores_id_sorted = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ADF88B\"> Model and Test information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['tiny', 'nb-whisper-tiny', 'nb-whisper-tiny-verbatim',\n",
    "        'base', 'nb-whisper-base', 'nb-whisper-base-verbatim',\n",
    "        'medium', 'nb-whisper-medium', 'nb-whisper-medium-verbatim']\n",
    "\n",
    "different_tests = [\n",
    "'__concatenated_audio_information_scores_id_sorted', # 1\n",
    "'__concatenated_audio_information_scores_id_mixed', # 2\n",
    "# '__concatenated_audio_information_by_id', # 3\n",
    "'__concatenated_audio_information_group_id_sorted_score', # 3\n",
    "'__concatenated_audio_information_no_group_mixed'] # 4\n",
    "\n",
    "test_names = ['Grouped by score, sorted IDs', \n",
    "        'Grouped by score, mixed IDs',\n",
    "        'Grouped by ID: sorted scores',\n",
    "        'No groups, mixed data']\n",
    "\n",
    "\n",
    "info_dir ='./3x10_Concatenation_information'\n",
    "figure_dir = './Concat_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F9F871\"> Data Preprocessing </span>\n",
    "Teh trannskribed files are a bit wrong. There for each file are changed. \n",
    "\n",
    "Changes done:\n",
    "* Remove unused columns\n",
    "* Rename columns\n",
    "* Calculate CER and WER correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_score</th>\n",
       "      <th>input_string</th>\n",
       "      <th>translated_string</th>\n",
       "      <th>translated_CER</th>\n",
       "      <th>translated_WER</th>\n",
       "      <th>target_WER</th>\n",
       "      <th>unique_id's</th>\n",
       "      <th>speaker_id's</th>\n",
       "      <th>length_deviation_words</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>input_string_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>øre sjakk rød planke ødelagt glorie krakk blå ...</td>\n",
       "      <td>det er jo noen det er jo noen det er jo noen d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>['d19', 'd16', 'd17', 'd11', 'd13', 'd09']</td>\n",
       "      <td>['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...</td>\n",
       "      <td>6</td>\n",
       "      <td>words_0_10.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_1_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>korn tjern skulder skjørt støvel pluss sjø grø...</td>\n",
       "      <td>upp sjeg hjeg hjeg hjeg hjeg hjeg hjeg hjeg hj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>['a30', 'd07', 'd08', 'a34']</td>\n",
       "      <td>['d08', 'd08', 'd08', 'd08', 'd08', 'd08', 'd0...</td>\n",
       "      <td>102</td>\n",
       "      <td>words_10_20.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_1_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>glorie klo kjerne hylle fregner brun bryter fl...</td>\n",
       "      <td>blåle blåle pren heller plain blåle blåle blål...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d19']</td>\n",
       "      <td>['d19', 'd19', 'd19', 'd19', 'd19', 'd19', 'd1...</td>\n",
       "      <td>0</td>\n",
       "      <td>words_0_10.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_2_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>skive søppel skøyter trapp skitten løve premie...</td>\n",
       "      <td>fjølkje fjølkje fjølkje fjølkje fjølkje fjølkj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d19', 'd17', 'd16']</td>\n",
       "      <td>['d19', 'd19', 'd19', 'd19', 'd19', 'd19', 'd1...</td>\n",
       "      <td>1</td>\n",
       "      <td>words_10_20.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_2_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>plystre kvern glorie klem bryter briller drue ...</td>\n",
       "      <td>pristre kva? klo kram bt bl dv bl dv bl dv bl ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d15', 'd14', 'd13', 'd16']</td>\n",
       "      <td>['d16', 'd15', 'd14', 'd14', 'd14', 'd14', 'd1...</td>\n",
       "      <td>102</td>\n",
       "      <td>words_20_30.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_2_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>turn trylle troll tre trapp tralle torne tjern...</td>\n",
       "      <td>tjør tjør tjør tjør tjør tjør tjør tjør tjør t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d17']</td>\n",
       "      <td>['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...</td>\n",
       "      <td>79</td>\n",
       "      <td>words_270_280.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_5_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>synge sykkel syk skjerf øre nøkkel mus munn ly...</td>\n",
       "      <td>sikker sikker sajf døne nåkkel nåkkel nåkkel l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d17']</td>\n",
       "      <td>['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...</td>\n",
       "      <td>0</td>\n",
       "      <td>words_280_290.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_5_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>lue løve løpe kvart kurv skjema plante pluss s...</td>\n",
       "      <td>løve løve løve løve kjån kjån kjån sjema plong...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d17']</td>\n",
       "      <td>['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...</td>\n",
       "      <td>2</td>\n",
       "      <td>words_290_300.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_5_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>skive skilpadde sjø skjære rød pute prins prem...</td>\n",
       "      <td>siva siva, bap sjo kjærde hjø pyrtte pyrtte py...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d17']</td>\n",
       "      <td>['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...</td>\n",
       "      <td>4</td>\n",
       "      <td>words_300_310.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_5_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>hjort hjerne gutt gul garn glitter glad gartne...</td>\n",
       "      <td>hjort ja, ne gist gyr gann littet gla gart nør...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['d16']</td>\n",
       "      <td>['d16', 'd16', 'd16', 'd16', 'd16', 'd16', 'd1...</td>\n",
       "      <td>2</td>\n",
       "      <td>words_310_320.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_5_sorted</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_score                                       input_string  \\\n",
       "0              1  øre sjakk rød planke ødelagt glorie krakk blå ...   \n",
       "1              1  korn tjern skulder skjørt støvel pluss sjø grø...   \n",
       "2              2  glorie klo kjerne hylle fregner brun bryter fl...   \n",
       "3              2  skive søppel skøyter trapp skitten løve premie...   \n",
       "4              2  plystre kvern glorie klem bryter briller drue ...   \n",
       "..           ...                                                ...   \n",
       "90             5  turn trylle troll tre trapp tralle torne tjern...   \n",
       "91             5  synge sykkel syk skjerf øre nøkkel mus munn ly...   \n",
       "92             5  lue løve løpe kvart kurv skjema plante pluss s...   \n",
       "93             5  skive skilpadde sjø skjære rød pute prins prem...   \n",
       "94             5  hjort hjerne gutt gul garn glitter glad gartne...   \n",
       "\n",
       "                                    translated_string  translated_CER  \\\n",
       "0   det er jo noen det er jo noen det er jo noen d...             NaN   \n",
       "1   upp sjeg hjeg hjeg hjeg hjeg hjeg hjeg hjeg hj...             NaN   \n",
       "2   blåle blåle pren heller plain blåle blåle blål...             NaN   \n",
       "3   fjølkje fjølkje fjølkje fjølkje fjølkje fjølkj...             NaN   \n",
       "4   pristre kva? klo kram bt bl dv bl dv bl dv bl ...             NaN   \n",
       "..                                                ...             ...   \n",
       "90  tjør tjør tjør tjør tjør tjør tjør tjør tjør t...             NaN   \n",
       "91  sikker sikker sajf døne nåkkel nåkkel nåkkel l...             NaN   \n",
       "92  løve løve løve løve kjån kjån kjån sjema plong...             NaN   \n",
       "93  siva siva, bap sjo kjærde hjø pyrtte pyrtte py...             NaN   \n",
       "94  hjort ja, ne gist gyr gann littet gla gart nør...             NaN   \n",
       "\n",
       "    translated_WER  target_WER                                 unique_id's  \\\n",
       "0              NaN         0.7  ['d19', 'd16', 'd17', 'd11', 'd13', 'd09']   \n",
       "1              NaN         0.3                ['a30', 'd07', 'd08', 'a34']   \n",
       "2              NaN         1.0                                     ['d19']   \n",
       "3              NaN         1.0                       ['d19', 'd17', 'd16']   \n",
       "4              NaN         1.0                ['d15', 'd14', 'd13', 'd16']   \n",
       "..             ...         ...                                         ...   \n",
       "90             NaN         1.0                                     ['d17']   \n",
       "91             NaN         1.0                                     ['d17']   \n",
       "92             NaN         1.0                                     ['d17']   \n",
       "93             NaN         1.0                                     ['d17']   \n",
       "94             NaN         1.0                                     ['d16']   \n",
       "\n",
       "                                         speaker_id's  length_deviation_words  \\\n",
       "0   ['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...                       6   \n",
       "1   ['d08', 'd08', 'd08', 'd08', 'd08', 'd08', 'd0...                     102   \n",
       "2   ['d19', 'd19', 'd19', 'd19', 'd19', 'd19', 'd1...                       0   \n",
       "3   ['d19', 'd19', 'd19', 'd19', 'd19', 'd19', 'd1...                       1   \n",
       "4   ['d16', 'd15', 'd14', 'd14', 'd14', 'd14', 'd1...                     102   \n",
       "..                                                ...                     ...   \n",
       "90  ['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...                      79   \n",
       "91  ['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...                       0   \n",
       "92  ['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...                       2   \n",
       "93  ['d17', 'd17', 'd17', 'd17', 'd17', 'd17', 'd1...                       4   \n",
       "94  ['d16', 'd16', 'd16', 'd16', 'd16', 'd16', 'd1...                       2   \n",
       "\n",
       "           audio_name                                  audio_path  \\\n",
       "0      words_0_10.wav  ../3x10_Concatenations/3x10_score_1_sorted   \n",
       "1     words_10_20.wav  ../3x10_Concatenations/3x10_score_1_sorted   \n",
       "2      words_0_10.wav  ../3x10_Concatenations/3x10_score_2_sorted   \n",
       "3     words_10_20.wav  ../3x10_Concatenations/3x10_score_2_sorted   \n",
       "4     words_20_30.wav  ../3x10_Concatenations/3x10_score_2_sorted   \n",
       "..                ...                                         ...   \n",
       "90  words_270_280.wav  ../3x10_Concatenations/3x10_score_5_sorted   \n",
       "91  words_280_290.wav  ../3x10_Concatenations/3x10_score_5_sorted   \n",
       "92  words_290_300.wav  ../3x10_Concatenations/3x10_score_5_sorted   \n",
       "93  words_300_310.wav  ../3x10_Concatenations/3x10_score_5_sorted   \n",
       "94  words_310_320.wav  ../3x10_Concatenations/3x10_score_5_sorted   \n",
       "\n",
       "    input_string_len  \n",
       "0                 10  \n",
       "1                 10  \n",
       "2                 10  \n",
       "3                 10  \n",
       "4                 10  \n",
       "..               ...  \n",
       "90                10  \n",
       "91                10  \n",
       "92                10  \n",
       "93                10  \n",
       "94                10  \n",
       "\n",
       "[95 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'speaker_id','score',\n",
    "# 'input_string','translated_string',\n",
    "# 'translated_CER','translated_WER',\n",
    "# 'target_CER','target_WER',\n",
    "# 'length_deviation_words','audio_name','audio_path'\n",
    "\n",
    "file_list = os.listdir(info_dir)\n",
    "\n",
    "for data in file_list:\n",
    "    data_path = os.path.join(info_dir, data)\n",
    "    sigma_df = pd.read_csv(data_path)\n",
    "    \n",
    "    # 'translated_CER','translated_WER'\n",
    "    sigma_df = sigma_df.drop(columns=['trans_CER','trans_WER', 'target_CER', 'target_CER_sum'])\n",
    "    sigma_df = sigma_df.rename(columns={'score':'global_score'})                                                                                      \n",
    "\n",
    "    # # --- Extract and modify the model name for plotting --- # \n",
    "    # model_name = data.split('__')[0] \n",
    "    # if model_name.startswith('nb'):\n",
    "    #     mn_split = model_name.split('-whisper')\n",
    "    #     if not len(mn_split) == 2:\n",
    "    #         print(f'Error: model name split failed. Len: {len(mn_split)}. Split: {mn_split}')\n",
    "    #     else:\n",
    "    #         model_name = 'NNL' + mn_split[1]\n",
    "    # else:\n",
    "    #     model_name = model_name.capitalize()\n",
    "        \n",
    "    # sigma_df['model_name'] = model_name\n",
    "    \n",
    "    # --- Calculate correct WER --- # \n",
    "    sigma_df['input_string_len'] = sigma_df['input_string'].apply(lambda x: len(x.split(' ')))\n",
    "    \n",
    "    for idx, row in sigma_df.iterrows():\n",
    "        \n",
    "        \n",
    "        \n",
    "        sigma_df.at[idx, 'correct_WER'] = row['target_WER'] / row['input_string_len']\n",
    "    \n",
    "    sigma_df['correct_WER'] = \n",
    "    \n",
    "    # sigma_df['target_WER'] = sigma_df.apply(lambda row: row['target_WER'] / row['input_string_len'], axis=1)\n",
    "    \n",
    "    # sigma_df = sigma_df.drop(columns=['trans_WER'])\n",
    "    \n",
    "    # reorder_column = [\"global_score\", \n",
    "    #                 'input_string', 'translated_string',\n",
    "    #                 'target_WER', \n",
    "    #                 'translated_CER', 'translated_WER', 'model_name',                         \n",
    "                    \n",
    "    #                 \"target_word\", \"PER\", \n",
    "    #                 \"transcribed_word\", \"CER\", \n",
    "    #                 \"transcribed_word_striped\", \"striped_CER\",\n",
    "    #                 \"file_name\", \"model_name\"]\n",
    "    \n",
    "    # beta_df = beta_df[reorder_column]\n",
    "sigma_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Whisper model tiny, is the deviation in extra words transcribed big for the lower score, and it gets smaller for higher score, but then the outliers are way bigger than at the lower scores.\n",
    "\n",
    "See: \n",
    "* Audio clip: 22 -> 210_220: Transcribed a longer sentence than the target sentence.\n",
    "* Audio clip: 20 -> It has 23 unique transcriptions whit no extra words.\n",
    "\n",
    "\n",
    "<span style=\"color:#FF6F91\"> **Test categories:**\n",
    "\n",
    "1. <span style=\"color:#FF9671\"> Grouping by score, sorted IDs : <code> {model_name}__concatenated_audio_information_scores_id_sorted </code></span>\n",
    "2. <span style=\"color:#FFC75F\"> Grouping by score, mixed IDs  : <code> {model_name}__concatenated_audio_information_scores_id_mixed </code></span>\n",
    "\n",
    "<!-- 3. <span style=\"color:#F9F871\"> Grouping by IDs: sorted scores: <code> {model_name}__concatenated_audio_information_by_id</code> </span> -->\n",
    "3. <span style=\"color:#F9F871\"> Grouping by IDs: sorted scores: <code> {model_name}__concatenated_audio_information_group_id_sorted_score</code> </span>\n",
    "4. <span style=\"color:#FF6F91\"> Random shuffling: no group    : <code> {model_name}__concatenated_audio_information_no_group_mixed </code></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: scores_id_sorted\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(different_tests):\n",
    "    # Get the name of the current test\n",
    "    current_test = test.split('information_')[1]\n",
    "    \n",
    "    # --- Define and create the directory to save the plots --- #\n",
    "    name = f'Test {idx+1}: {current_test}'\n",
    "    save_dir = os.path.join(figure_dir, name)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f'Created directory: {save_dir}')\n",
    "    print(name)\n",
    "    \n",
    "    # --- Get the list of file names for the current test --- #\n",
    "    test_lst = os.listdir(info_dir)\n",
    "    this_test_list = [file for file in test_lst if file.endswith(f'{current_test}_v1.csv')]\n",
    "    if len(this_test_list) != 9: # The list is wrong if this is triggered\n",
    "        print(f'Error: {len(this_test_list)} files found for {current_test}')\n",
    "        break\n",
    "    \n",
    "    # --- Create a big data frame and concatenate all the data --- #\n",
    "    the_chad_df = pd.DataFrame()\n",
    "    \n",
    "    for data in this_test_list:\n",
    "        data_path = os.path.join(info_dir, data)\n",
    "        beta_df = pd.read_csv(data_path)\n",
    "        model_name = data.split('__')[0] \n",
    "        \n",
    "        # --- Extract and modify the model name for plotting --- # \n",
    "        if model_name.startswith('nb'):\n",
    "            mn_split = model_name.split('-whisper')\n",
    "            if not len(mn_split) == 2:\n",
    "                print(f'Error: model name split failed. Len: {len(mn_split)}. Split: {mn_split}')\n",
    "            else:\n",
    "                model_name = 'NNL' + mn_split[1]\n",
    "        else:\n",
    "            model_name = model_name.capitalize()\n",
    "            \n",
    "            # Drop this: 'length_deviation_words','audio_name','audio_path'\n",
    "            \n",
    "        beta_df['model_name'] = model_name\n",
    "        \n",
    "        reorder_column = [\"global_score\", \n",
    "                        'input_string', 'translated_string',\n",
    "                        'target_WER', \n",
    "                        'translated_CER', 'translated_WER', 'model_name',                         \n",
    "                        \n",
    "                        \"target_word\", \"PER\", \n",
    "                        \"transcribed_word\", \"CER\", \n",
    "                        \"transcribed_word_striped\", \"striped_CER\",\n",
    "                        \"file_name\", \"model_name\"]\n",
    "        \n",
    "        beta_df = beta_df[reorder_column]\n",
    "        print(len(beta_df.columns.values))\n",
    "        \n",
    "        # --- Concatenate the data --- #\n",
    "        the_chad_df = pd.concat([the_chad_df, beta_df], axis=0)\n",
    "    \n",
    "    \n",
    "    # for model in models:\n",
    "        \n",
    "    #     file_name = model + test + '_v1.csv'\n",
    "    #     scores_id_sorted = pd.read_csv(file_name)\n",
    "    #     smf.plot_concatenation_information(scores_id_sorted, model, save_dir)\n",
    "    # # for model in models:\n",
    "    # #     file_name = model + test + '_v1.csv'\n",
    "    # #     scores_id_sorted = pd.read_csv(file_name)\n",
    "    break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>input_string</th>\n",
       "      <th>translated_string</th>\n",
       "      <th>target_CER</th>\n",
       "      <th>target_CER_sum</th>\n",
       "      <th>target_WER</th>\n",
       "      <th>unique_id's</th>\n",
       "      <th>speaker_id's</th>\n",
       "      <th>length_deviation_words</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>translated_CER</th>\n",
       "      <th>translated_WER</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>øre sjakk rød planke ødelagt glorie krakk blå ...</td>\n",
       "      <td>fly flakt roe</td>\n",
       "      <td>[0.3333333333333333, 0.0, 0.0, 0.3333333333333...</td>\n",
       "      <td>3.028571</td>\n",
       "      <td>0.7</td>\n",
       "      <td>['d19', 'd16', 'd17', 'd11', 'd13', 'd09']</td>\n",
       "      <td>['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...</td>\n",
       "      <td>-7</td>\n",
       "      <td>words_0_10.wav</td>\n",
       "      <td>../3x10_Concatenations/3x10_score_1_sorted</td>\n",
       "      <td>0.8596491228070176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNL-medium-verbatim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                       input_string translated_string  \\\n",
       "0      1  øre sjakk rød planke ødelagt glorie krakk blå ...     fly flakt roe   \n",
       "\n",
       "                                          target_CER  target_CER_sum  \\\n",
       "0  [0.3333333333333333, 0.0, 0.0, 0.3333333333333...        3.028571   \n",
       "\n",
       "   target_WER                                 unique_id's  \\\n",
       "0         0.7  ['d19', 'd16', 'd17', 'd11', 'd13', 'd09']   \n",
       "\n",
       "                                        speaker_id's  length_deviation_words  \\\n",
       "0  ['d19', 'd19', 'd19', 'd17', 'd17', 'd16', 'd1...                      -7   \n",
       "\n",
       "       audio_name                                  audio_path  \\\n",
       "0  words_0_10.wav  ../3x10_Concatenations/3x10_score_1_sorted   \n",
       "\n",
       "       translated_CER  translated_WER           model_name  \n",
       "0  0.8596491228070176             1.0  NNL-medium-verbatim  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the_chad_df[the_chad_df['translated_CER']]\n",
    "# the_chad_df['translated_CER'][0]\n",
    "# Want to know where the the_chad_df['translated_CER'] is not NaN\n",
    "the_chad_df['trans_WER'].notnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
