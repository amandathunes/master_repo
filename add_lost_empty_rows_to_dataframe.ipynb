{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resave Empty Strings\n",
    "\n",
    "Script to find the different between to data frames in case the empty data frame is not saved.\n",
    "\n",
    "Was used for the First Batch transcriptions, and the the versjon 1 transcriptions..\n",
    "\n",
    "How to use: \n",
    "\n",
    "Defind the following variables in the script:\n",
    "* The directory path \n",
    "* What trascription files to look for\n",
    "* Wanted name for the output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind this and then run the script\n",
    "# dir_path = './Transcriptions/Fist_batch_of_transcriptions/'\n",
    "dir_path = './Transcriptions/'\n",
    "name2look4 = 'trans'\n",
    "output_name = 'empty_transcriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import self_made_functions as smf\n",
    "import prettytable as pt\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "df_fin, _ = smf.get_df()\n",
    "tab = pt.PrettyTable()\n",
    "tab.field_names = ['Name', 'Lenght of missing df']\n",
    "tab.align = 'l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump over file : Fist_batch_of_transcriptions \n",
      "\n",
      "Jump over file : eMpTy_FiLe.csv \n",
      "\n",
      "+----------------------------+----------------------+\n",
      "| Name                       | Lenght of missing df |\n",
      "+----------------------------+----------------------+\n",
      "| tiny                       | 0                    |\n",
      "| base                       | 3                    |\n",
      "| medium                     | 0                    |\n",
      "| nb-whisper-tiny            | 0                    |\n",
      "| nb-whisper-base            | 35                   |\n",
      "| nb-whisper-medium          | 24                   |\n",
      "| nb-whisper-tiny-verbatim   | 0                    |\n",
      "| nb-whisper-medium-verbatim | 1                    |\n",
      "| nb-whisper-base-verbatim   | 98                   |\n",
      "+----------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Shift throug the directory and finding the missing words from the original data frame df_fin\n",
    "lst = os.listdir(dir_path)\n",
    "mt = pd.DataFrame(columns=['File name', 'Word', 'idx', 'Model'])\n",
    "\n",
    "for cvs_files in lst: # - # - # BE SURE THIS IS THE RIGHT FILEs\n",
    "    # print(cvs_files)\n",
    "    if str(cvs_files).startswith(name2look4):\n",
    "        df_look_at = pd.read_csv(os.path.join(dir_path, cvs_files))\n",
    "        missing_words = smf.find_missing_words(df_fin, df_look_at)\n",
    "        \n",
    "        model_name = cvs_files.split('_')[1].split('.')[0] # this could change\n",
    "        \n",
    "        new_row = pd.DataFrame(columns=mt.columns)\n",
    "        for idx, file_name in enumerate(missing_words):\n",
    "            word = df_fin['Word'][df_fin['File name'] == file_name].values[0]\n",
    "            id = df_fin[df_fin['File name'] == file_name].index[0]\n",
    "            \n",
    "            new_row.loc[idx] = [file_name, word, id, model_name]\n",
    "        \n",
    "        new_row = new_row.sort_values(by='idx')\n",
    "        mt = pd.concat([mt, new_row], ignore_index=True)\n",
    "        \n",
    "        tab.add_row([model_name, len(missing_words)])\n",
    "    else:\n",
    "        print('Jump over file :', cvs_files, '\\n')\n",
    "\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to csv : ./Transcriptions/empty_transcriptions_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# Run this to save the empty transcriptions to a new csv file\n",
    "new_name = smf.get_new_csv_name(dir_path, output_name)\n",
    "print('Write to csv :', new_name)\n",
    "\n",
    "mt.to_csv(new_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is how the find missing words works\n",
    "# # Test out before doing it to all the files in the directory\n",
    "# df1 = df_fin[['File name','Word']]\n",
    "\n",
    "# path = './Transcriptions/Fist_batch_of_transcriptions/transcriptions_nb-whisper-base-verbatim.csv'\n",
    "# df2 = pd.read_csv(path)\n",
    "# df2 = df2[['File name','Word']]\n",
    "\n",
    "# words_df1 = set(df1['File name'])  # Convert the 'words' column in df1 to a set\n",
    "# words_df2 = set(df2['File name'])  # Convert the 'words' column in df2 to a set\n",
    "\n",
    "# # Find words in df1 that are not in df2 - assume those are the empty transcriptions left out\n",
    "# missing_words = words_df1.difference(words_df2)\n",
    "# print(missing_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
