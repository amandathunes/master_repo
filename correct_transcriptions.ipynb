{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â£ All transcriptions are wrong due to old def of data frame drop used. Make new ones to test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 08:49:12.445096: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 08:49:13.790949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import self_made_functions as smf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data_path = '/talebase/data/speech_raw/teflon_no/'\n",
    "path_all_audio = data_path + 'speech16khz/'\n",
    "\n",
    "# Data frame fixing -------------\n",
    "df_new_assessment = pd.read_csv(data_path + 'assessments.csv') # Loade file\n",
    "df_new_no_zero = df_new_assessment[df_new_assessment['Score'] != 0] # Remove Zero scores\n",
    "\n",
    "# Get the index of the max score for each file name group\n",
    "max_score_indices = df_new_no_zero.groupby('File name')['Score'].idxmax() \n",
    "df_new_no_dup = df_new_no_zero.loc[max_score_indices]\n",
    "\n",
    "# Get the mean score for each file name group\n",
    "mean_scores = df_new_no_zero.groupby('File name')['Score'].mean().apply(np.ceil).astype(int)\n",
    "\n",
    "# Replace the 'Score' column with the rounded mean scores\n",
    "df_new_no_dup['Score'] = df_new_no_dup['File name'].map(mean_scores)\n",
    "df_new_no_dup.reset_index(drop=True, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assessment = df_new_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [#'tiny', 'nb-whisper-tiny', 'nb-whisper-tiny-verbatim',\n",
    "                #'base', 'nb-whisper-base', 'nb-whisper-base-verbatim',\n",
    "                'medium', 'nb-whisper-medium', 'nb-whisper-medium-verbatim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 of 9322\n",
      "Index 900 of 9322\n",
      "Index 1800 of 9322\n",
      "Index 2700 of 9322\n",
      "Index 3600 of 9322\n",
      "Index 4500 of 9322\n",
      "Index 5400 of 9322\n",
      "Index 6300 of 9322\n",
      "Index 7200 of 9322\n",
      "Index 8100 of 9322\n",
      "Index 9000 of 9322\n",
      "Finished transcribing all the words in medium\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 of 9322\n",
      "Index 900 of 9322\n",
      "Index 1800 of 9322\n",
      "Index 2700 of 9322\n",
      "Index 3600 of 9322\n",
      "Index 4500 of 9322\n",
      "Index 5400 of 9322\n",
      "Index 6300 of 9322\n",
      "Index 7200 of 9322\n",
      "Index 8100 of 9322\n",
      "Index 9000 of 9322\n",
      "Finished transcribing all the words in nb-whisper-medium\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 of 9322\n",
      "Index 900 of 9322\n",
      "Index 1800 of 9322\n",
      "Index 2700 of 9322\n",
      "Index 3600 of 9322\n",
      "Index 4500 of 9322\n",
      "Index 5400 of 9322\n",
      "Index 6300 of 9322\n",
      "Index 7200 of 9322\n",
      "Index 8100 of 9322\n",
      "Index 9000 of 9322\n",
      "Finished transcribing all the words in nb-whisper-medium-verbatim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    \n",
    "    # --------  MODEL SETUP -------- #\n",
    "    model_name_path = smf.get_whisper_path(model_name)\n",
    "    model = pipeline(\"automatic-speech-recognition\", model_name_path) # Load the model\n",
    "    print(f\"Loaded the whisper model {model_name}\")\n",
    "    \n",
    "    model_transcriptions = pd.DataFrame(columns=['File name', 'Word', 'Transcribed', \n",
    "                                'CER (Character Error Rate)', 'CER Score'])  \n",
    "    \n",
    "    # -------- TRANSCRIPTION --------  #\n",
    "    for i, row in df_assessment.iterrows(): # Iterate over the data frame\n",
    "        audio_path = path_all_audio + row['File name']\n",
    "        transcription = model(audio_path, generate_kwargs={'task': 'transcribe', 'language': 'no'}) \n",
    "        \n",
    "        # Checks for empty strings in transcriptions\n",
    "        if 'text' in transcription and transcription['text'].strip(): \n",
    "            # -------- Calculate CER -------- #\n",
    "            cer = jiwer.cer(transcription['text'], row['Word'])\n",
    "            \n",
    "            model_transcriptions.loc[i] = [row['File name'], \n",
    "                                        row['Word'], transcription['text'], \n",
    "                                        cer, row['Score']] # Directly add a new row to the DataFrame    \n",
    "        # else: # If the transcription is empty -->--> handle_empty_translations.ipynb <--<--\n",
    "            \n",
    "            \n",
    "        # if i == 2: # Used to test if the files are saved whit the correct name\n",
    "        #     index_empty_rows = [1, 2, 3] \n",
    "        #     break  # Quick test to see if the code works\n",
    "        \n",
    "        # Have consistent prints so the server does not disconnect\n",
    "        if i % 900 == 0: print(f'Index {i} of {len(df_assessment)}') \n",
    "        \n",
    "    print(f\"Finished transcribing all the words in {model_name}\\n\")\n",
    "    \n",
    "    # -------- Save CVS -------- #\n",
    "    try: \n",
    "        # CVS name\n",
    "        transcription_dir = './Transcriptions'\n",
    "        base_name = f'true_transcription_{model_name}'\n",
    "        csv_file_name, number = smf.get_new_csv_name(transcription_dir, base_name)\n",
    "        # Use \"\"./Final Scripts/handle_empty_translations.ipynb\" To get the empty transcriptions\n",
    "        \n",
    "        model_transcriptions.to_csv(csv_file_name, index=False) \n",
    "        \n",
    "    except Exception as e: # If it can't save it for some reason print the df\n",
    "        print(f'Error saving the transcribed whisper model {model_name} to csv: {e}') \n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
