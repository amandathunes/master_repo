{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning WhisperÂ¨\n",
    "\n",
    "The dataset for Whisper training involves \n",
    "1) audio segments converted into Log-mel spectrograms as input features.\n",
    "2) their corresponding text transcripts as targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/ajtruyen/anaconda3/envs/master_amanda/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:1712: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "model_name = \"NbAiLab/nb-whisper-base\"  # Example model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:49:38.122119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 13:49:39.267032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my_dataset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m---> 50\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m get_dataset(val_dir)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor(speech, sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     40\u001b[0m files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 41\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspeaker_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspeaker_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspeaker_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/master_amanda/lib/python3.12/pathlib.py:1056\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    The children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    special entries '.' and '..' are not included.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1057\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_child_relpath(name)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_dataset/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, TrainingArguments, Trainer\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"my_dataset\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "# Load the processor and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Initialize the trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=lambda eval_pred: {\"accuracy\": (eval_pred[0] == eval_pred[1]).mean()},\n",
    "    train_dataset=None,  # Will be loaded dynamically\n",
    "    eval_dataset=None,  # Will be loaded dynamically\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# Dynamically load datasets\n",
    "def get_dataset(split):\n",
    "    def _load_data(file_path):\n",
    "        speech, _ = librosa.load(file_path, sr=16000)\n",
    "        return processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True, truncation=True)[\"input_values\"]\n",
    "\n",
    "    files = []\n",
    "    for speaker_dir in Path(split).iterdir():\n",
    "        if speaker_dir.is_dir():\n",
    "            for file in speaker_dir.glob(\"*.wav\"):\n",
    "                files.append((file, _load_data(file)))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(files)\n",
    "    dataset = dataset.map(lambda x: x[1], num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(train_dir)\n",
    "val_dataset = get_dataset(val_dir)\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate(eval_dataset=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import self_made_functions as smf\n",
    "\n",
    "df_fin, wv_path = smf.get_df()\n",
    "df = df_fin[['File name', 'Word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File name</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a06_hylle.wav</td>\n",
       "      <td>hylle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       File name   Word\n",
       "0  a06_hylle.wav  hylle"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File name</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a06_hylle.wav</td>\n",
       "      <td>hylle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       File name   Word\n",
       "0  a06_hylle.wav  hylle"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = df[['File name', 'Word']]\n",
    "dataset.head(1)\n",
    "# Data frame fixing -------------\n",
    "\n",
    "    \n",
    "# # Function to load dataset from CSV\n",
    "# def load_my_dataset(data_dir, split='train'):\n",
    "#     csv_file = f\"{split}.csv\"\n",
    "#     dataset = pd.read_csv(path)\n",
    "    \n",
    "#     dataset = load_dataset('csv', data_files=f\"{data_dir}/{csv_file}\", split=split)\n",
    "#     return dataset\n",
    "\n",
    "# # Load the dataset\n",
    "# train_dataset = load_my_dataset('/project/data', split='train')\n",
    "# val_dataset = load_my_dataset('/project/data', split='val')\n",
    "\n",
    "# # Print the first entry to verify\n",
    "# print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into traing and test dataset\n",
    "# 80% - 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Splits the data into traing and test dataset. It shuffel the data and splits it randomly\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File name</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>a12_skjema.wav</td>\n",
       "      <td>skjema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File name    Word\n",
       "2183  a12_skjema.wav  skjema"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare fro traing whit whisper\n",
    "def prepare_dataframes_for_model(df):\n",
    "    modified_paths = [wv_path + row['File name'] for _, row in df.iterrows()]\n",
    "    return [(modified_paths, row['Word']) for _, row in df.iterrows()]\n",
    "\n",
    "train_data = prepare_dataframes_for_model(train_df)\n",
    "test_data = prepare_dataframes_for_model(test_df)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "\n",
    "# Load the tokenizer and model\n",
    "# NbAiLab/nb-whisper-tiny\n",
    "my_model = 'NbAiLab/nb-whisper-tiny'\n",
    "tokenizer = AutoTokenizer.from_pretrained(my_model)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(my_model)\n",
    "\n",
    "# Tokenize the training data\n",
    "train_encodings = tokenizer([text for _, text in train_data], truncation=True, padding=True)\n",
    "\n",
    "# Convert the test data into encodings\n",
    "test_encodings = tokenizer([text for _, text in test_data], truncation=True, padding=True)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encodings,\n",
    "    eval_dataset=test_encodings,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
