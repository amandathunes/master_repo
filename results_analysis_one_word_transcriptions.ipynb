{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style=\"color:#845EC2\"> Results and Analysis:</span></b> <b><span style=\"color:#D65DB1\"> One word transcriptions</span></b>\n",
    "\n",
    "<!-- <b><span style=\"color:#d65db1\"> ★ ★ ★ ★ </span></b>\n",
    "\n",
    "<b><span style=\"color:#de7dc1\"> ★ ★ ★ ★  </span></b>\n",
    "\n",
    "<b><span style=\"color:#e69ed0\"> ★ ★ ★ ★ </span></b>\n",
    "\n",
    "<b><span style=\"color:#efbee0\"> ★ ★ ★ ★</span></b> -->\n",
    "\n",
    "Focus on <b><span style=\"color:#FF9671\"> version 1 </span></b> in the first instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style=\"color:#b59eda\"> Libary Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library inmports\n",
    "import self_made_functions as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from   textwrap import wrap \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style=\"color:#e69ed0\"> Data initialization  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assessment, wv_path = smf.get_correct_df()\n",
    "\n",
    "# Make a new directory for resaved files \n",
    "results_dir = './Transcriptions/Results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Directory {results_dir} created\")\n",
    "\n",
    "# Read empty transcriptions\n",
    "empty_transcriptions = pd.read_csv('Transcriptions/empty_transcriptions_v1.csv')\n",
    "\n",
    "# Transcription directory information\n",
    "transcription_dir = './Transcriptions'\n",
    "lst_csv = os.listdir(transcription_dir)\n",
    "lst_csv = [file for file in lst_csv if file.startswith('tran') & file.endswith('v1.csv')] # The v1 transcribed files\n",
    "\n",
    "# Sort the list by model name\n",
    "test_for_models = ['tiny', 'nb-whisper-tiny', 'nb-whisper-tiny-verbatim',\n",
    "                    'base', 'nb-whisper-base', 'nb-whisper-base-verbatim',\n",
    "                    'medium', 'nb-whisper-medium', 'nb-whisper-medium-verbatim']\n",
    "lst_csv = sorted(lst_csv, key=lambda x: test_for_models.index(x.split('_')[-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b><span style=\"color:#e69ed0\"> Save missing information </span></b>\n",
    "\n",
    " The transcription files are changed and re saved.\n",
    "\n",
    "The <b><span style=\"color:#ff9671\">empty-transcriptions</span></b> are added to the transcriptions.\n",
    "\n",
    "The <b><span style=\"color:#ff9671\">Phonetic Error Ratio (PER)</span></b> is calculated. \n",
    "\n",
    "A <b><span style=\"color:#ff9671\">ID column</span></b> is added, and all the colum names are <b><span style=\"color:#ff9671\">renamed</span></b> and organized.\n",
    "\n",
    "\n",
    "A column for the <b><span style=\"color:#ff9671\">model name</span></b> is also added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./Transcriptions/transcriptions_tiny_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "796  a01_sykkel.wav  sykkel      sikker                    0.333333         4\n",
      "          file_name target_word transcribed_word       CER  global_score  \\\n",
      "796  a01_sykkel.wav      sykkel           sikker  0.333333             4   \n",
      "\n",
      "    model_name  PER  \n",
      "796       tiny  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-tiny_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "795  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "795  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "          model_name  PER  \n",
      "795  nb-whisper-tiny  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-tiny-verbatim_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "795  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "795  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "                   model_name  PER  \n",
      "795  nb-whisper-tiny-verbatim  0.2  \n",
      "Reading ./Transcriptions/transcriptions_base_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "796  a01_sykkel.wav  sykkel      sikkel                    0.166667         4\n",
      "          file_name target_word transcribed_word       CER  global_score  \\\n",
      "796  a01_sykkel.wav      sykkel           sikkel  0.166667             4   \n",
      "\n",
      "    model_name  PER  \n",
      "796       base  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-base_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "794  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "794  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "          model_name  PER  \n",
      "794  nb-whisper-base  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-base-verbatim_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "792  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "792  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "                   model_name  PER  \n",
      "792  nb-whisper-base-verbatim  0.2  \n",
      "Reading ./Transcriptions/transcriptions_medium_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "796  a01_sykkel.wav  sykkel       sikil                         0.5         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "796  a01_sykkel.wav      sykkel            sikil  0.5             4   \n",
      "\n",
      "    model_name  PER  \n",
      "796     medium  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-medium_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "794  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "794  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "            model_name  PER  \n",
      "794  nb-whisper-medium  0.2  \n",
      "Reading ./Transcriptions/transcriptions_nb-whisper-medium-verbatim_v1.csv\n",
      "          File name    Word Transcribed  CER (Character Error Rate)  OG Score\n",
      "795  a01_sykkel.wav  sykkel      sykkel                         0.0         4\n",
      "          file_name target_word transcribed_word  CER  global_score  \\\n",
      "795  a01_sykkel.wav      sykkel           sykkel  0.0             4   \n",
      "\n",
      "                     model_name  PER  \n",
      "795  nb-whisper-medium-verbatim  0.2  \n"
     ]
    }
   ],
   "source": [
    "def resave_transcription_df(bool:True):\n",
    "    lst_path = [os.path.join(transcription_dir, file) for file in lst_csv]\n",
    "\n",
    "    # Iterate through the CSV files to add what is missing\n",
    "    for path in lst_path:    \n",
    "        # Read transcriped files\n",
    "        df_csv = pd.read_csv(path)\n",
    "        print(f\"Reading {path}\")\n",
    "        df_csv = df_csv.drop(['CER Output',\"CER Score\"], axis=1) # axis = 1 : drops column, = 0 : drops row \n",
    "        \n",
    "        # Fix the CER column\n",
    "        df_csv['Transcribed'] = df_csv['Transcribed'].apply(lambda x: x.strip()  if isinstance(x, str) else x)\n",
    "        df_csv['Transcribed'] = df_csv['Transcribed'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        df_csv['Transcribed'] = df_csv['Transcribed'].apply(lambda x: x.replace(\".\", \"\") if isinstance(x, str) else x)\n",
    "        df_csv['Transcribed'] = df_csv['Transcribed'].apply(lambda x: x.replace(\"!\", \"\") if isinstance(x, str) else x)\n",
    "        df_csv['Transcribed'] = df_csv['Transcribed'].apply(lambda x: x.replace(\"?\", \"\") if isinstance(x, str) else x)        \n",
    "        df_csv['CER (Character Error Rate)'] = df_csv.apply(lambda x: jiwer.cer(x['Word'], x['Transcribed']), axis=1)\n",
    "        \n",
    "        print(df_csv[df_csv['File name']=='a01_sykkel.wav'])\n",
    "        \n",
    "        # Add model name\n",
    "        model_name = path.split('_')[-2]\n",
    "        df_csv[\"model_name\"] = model_name\n",
    "        \n",
    "        # Change names\n",
    "        df_csv = df_csv.rename(columns={\"File name\": \"file_name\",\n",
    "                                    \"CER (Character Error Rate)\": \"CER\", # Character Error Rate (CER)\n",
    "                                    \"Word\": \"target_word\", \n",
    "                                    \"Transcribed\": \"transcribed_word\", \n",
    "                                    \"OG Score\": \"global_score\"})\n",
    "        \n",
    "        for i, row in df_csv.iterrows():\n",
    "            pron_lst = df_assessment[df_assessment['File name'] == row[\"file_name\"]].pronScores.values[0].split(' ')\n",
    "            pron_count = pron_lst.count('0')\n",
    "            per = pron_count/len(pron_lst)\n",
    "            df_csv.loc[i, \"PER\"] = per # Phonetic Error Rate (PER)\n",
    "        \n",
    "        df_csv = pd.concat([df_csv, empty_transcriptions[empty_transcriptions['model_name']==model_name]], ignore_index=True)\n",
    "        df_csv = df_csv.reset_index(drop=True)\n",
    "        \n",
    "        print(df_csv[df_csv['file_name']=='a01_sykkel.wav'])\n",
    "        \n",
    "        if len(df_csv.model_name.unique()) > 1:\n",
    "            print(f\"Error: {path} has more than one model name\")\n",
    "            break\n",
    "        \n",
    "        # Add ID column\n",
    "        df_csv[\"id\"] = df_csv[\"file_name\"].apply(lambda x: x.split('_')[0])\n",
    "        df_csv = df_csv.sort_values(by=['id'])\n",
    "        \n",
    "        # print(df_csv.columns)    \n",
    "        # Reorder column names\n",
    "        reorder_column = [\"id\", \"global_score\", \n",
    "                        \"target_word\", \"PER\", \n",
    "                        \"transcribed_word\", \"CER\", \n",
    "                        \"file_name\", \"model_name\"]\n",
    "        \n",
    "        df_csv = df_csv[reorder_column]\n",
    "        # print(df_csv.columns)   \n",
    "\n",
    "        if bool:\n",
    "            # Save the file\n",
    "            csv_name = path.split('/')[-1]\n",
    "            df_csv.to_csv(os.path.join(results_dir, csv_name), index=False)    \n",
    "            \n",
    "resave_transcription_df(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#FF6F91\"> BOX PLOT &nbsp;:&nbsp; </span>**\n",
    "#### <span style=\"color:#ebaed8\">  Every model compar &nbsp;:&nbsp; CER vs. PER for <b>Native</b>, <b>Non Native</b> and <b>all</b> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directory to save the box plots &nbsp; : &nbsp; <span style=\"color:#ebaed8\"> *./BoxPlots/Model_CER*</i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_box_cer = './Transcriptions/Results/BoxPlots/Model_CER'\n",
    "if not os.path.exists(save_dir_box_cer):\n",
    "    os.makedirs(save_dir_box_cer)\n",
    "    print(f\"Directory {save_dir_box_cer} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a fuction that works for both all, native and non-native speakers\n",
    "\n",
    "**Giga Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./Transcriptions/Results/transcriptions_tiny_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-tiny_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-tiny-verbatim_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_base_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-base_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-base-verbatim_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_medium_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-medium_v1.csv\n",
      "Reading ./Transcriptions/Results/transcriptions_nb-whisper-medium-verbatim_v1.csv\n"
     ]
    }
   ],
   "source": [
    "lst_path = [os.path.join(results_dir, file) for file in lst_csv]\n",
    "ggm = pd.DataFrame()\n",
    "# Iterate through the CSV files to add what is missing\n",
    "for path in lst_path:\n",
    "    print(f\"Reading {path}\")\n",
    "    df_csv = pd.read_csv(path)\n",
    "    ggm = pd.concat([ggm, df_csv], ignore_index=True)\n",
    "ggm = ggm.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
