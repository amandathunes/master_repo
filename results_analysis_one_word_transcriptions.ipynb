{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style=\"color:#845EC2\"> Results and Analysis:</span></b> <b><span style=\"color:#D65DB1\"> One word transcriptions</span></b>\n",
    "\n",
    "\n",
    "<!-- <b><span style=\"color:#845EC2\">845EC2</span></b>\n",
    "<b><span style=\"color:#D65DB1\">D65DB1</span></b>\n",
    "<b><span style=\"color:#FF6F91\">FF6F91</span></b>\n",
    "<b><span style=\"color:#FF9671\">FF9671</span></b>\n",
    "<b><span style=\"color:#FFC75F\">FFC75F</span></b>\n",
    "<b><span style=\"color:#F9F871\">F9F871</span></b>  -->\n",
    "\n",
    "<!-- <b><span style=\"color:#d65db1\"> ★ ★ ★ ★ </span></b>\n",
    "\n",
    "<b><span style=\"color:#de7dc1\"> ★ ★ ★ ★  </span></b>\n",
    "\n",
    "<b><span style=\"color:#e69ed0\"> ★ ★ ★ ★ </span></b>\n",
    "\n",
    "<b><span style=\"color:#efbee0\"> ★ ★ ★ ★</span></b> -->\n",
    "\n",
    "Focus on <b><span style=\"color:#FF9671\"> version 1 </span></b> in the first instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style=\"color:#b59eda\"> Libary Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 16:54:46.356378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 16:54:47.538782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import matplotlib.patches as mpatches\n",
    "import self_made_functions as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from   textwrap import wrap \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style=\"color:#e69ed0\"> Data initialization  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assessment, wv_path = smf.get_correct_df()\n",
    "\n",
    "# Make a new directory for resaved files \n",
    "results_dir = './Transcriptions/Results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Directory {results_dir} created\")\n",
    "\n",
    "# Read empty transcriptions\n",
    "empty_transcriptions = pd.read_csv('Transcriptions/empty_transcriptions_v1.csv')\n",
    "\n",
    "# Transcription directory information\n",
    "transcription_dir = './Transcriptions'\n",
    "lst_csv = os.listdir(transcription_dir)\n",
    "lst_csv = [file for file in lst_csv if file.startswith('tran') & file.endswith('v1.csv')] # The v1 transcribed files\n",
    "# lst_csv = [file for file in lst_csv if file.startswith('true') & file.endswith('v1.csv')] # The v1 transcribed files\n",
    "\n",
    "# Sort the list by model name\n",
    "test_for_models = ['tiny', 'nb-whisper-tiny', 'nb-whisper-tiny-verbatim',\n",
    "                    'base', 'nb-whisper-base', 'nb-whisper-base-verbatim',\n",
    "                    'medium', 'nb-whisper-medium', 'nb-whisper-medium-verbatim']\n",
    "lst_csv = sorted(lst_csv, key=lambda x: test_for_models.index(x.split('_')[-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b><span style=\"color:#e69ed0\"> Save missing information </span></b>\n",
    "\n",
    " The transcription files are changed and re saved.\n",
    "\n",
    "The <b><span style=\"color:#ff9671\">empty-transcriptions</span></b> are added to the transcriptions.\n",
    "\n",
    "The <b><span style=\"color:#ff9671\">Phonetic Error Ratio (PER)</span></b> is calculated. \n",
    "\n",
    "A <b><span style=\"color:#ff9671\">ID column</span></b> is added, and all the colum names are <b><span style=\"color:#ff9671\">renamed</span></b> and organized.\n",
    "\n",
    "\n",
    "A column for the <b><span style=\"color:#ff9671\">model name</span></b> is also added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resave_transcription_df(bool:True):\n",
    "    lst_path = [os.path.join(transcription_dir, file) for file in lst_csv]\n",
    "\n",
    "    # Iterate through the CSV files to add what is missing\n",
    "    for path in lst_path:    \n",
    "        # Read transcriped files\n",
    "        df_csv = pd.read_csv(path)\n",
    "        print(f\"Reading {path}\")\n",
    "        if 'CER Output' in df_csv.columns:\n",
    "            df_csv = df_csv.drop(['CER Output',\"CER Score\"], axis=1) # axis = 1 : drops column, = 0 : drops row \n",
    "        \n",
    "        # Fix the CER column - For comparison\n",
    "        df_csv['CER (Character Error Rate)'] = df_csv.apply(lambda x: jiwer.cer(x['Word'], x['Transcribed']), axis=1)\n",
    "        \n",
    "        # Add a column with the striped transcription and its corresponding CER.\n",
    "        # This is interning regarding the performance of the verbatim model.\n",
    "        # All transcriptions, excluding the empty transcriptions, are striped for all models, including verbatim.\n",
    "        df_csv['transcribed_word_striped'] = df_csv['Transcribed'].apply(\n",
    "            lambda x: x.strip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\") \n",
    "            if isinstance(x, str) else x)      \n",
    "        df_csv['striped_CER'] = df_csv.apply(lambda x: jiwer.cer(x['Word'], x['transcribed_word_striped']), axis=1)\n",
    "        # print(df_csv[df_csv['File name']=='a01_sykkel.wav'])\n",
    "        \n",
    "        # Add model name\n",
    "        model_name = path.split('_')[-2]\n",
    "        df_csv[\"model_name\"] = model_name\n",
    "        \n",
    "        # Change names\n",
    "        df_csv = df_csv.rename(columns={\"File name\": \"file_name\",\n",
    "                                    \"CER (Character Error Rate)\": \"CER\", # Character Error Rate (CER)\n",
    "                                    \"Word\": \"target_word\", \n",
    "                                    \"Transcribed\": \"transcribed_word\", \n",
    "                                    \"OG Score\": \"global_score\"})\n",
    "        \n",
    "        for i, row in df_csv.iterrows():\n",
    "            pron_lst = df_assessment[df_assessment['File name'] == row[\"file_name\"]].pronScores.values[0].split(' ')\n",
    "            pron_count = pron_lst.count('0')\n",
    "            per = pron_count/len(pron_lst)\n",
    "            df_csv.loc[i, \"PER\"] = per # Phonetic Error Rate (PER)\n",
    "        \n",
    "        df_csv = pd.concat([df_csv, empty_transcriptions[empty_transcriptions['model_name']==model_name]], ignore_index=True)\n",
    "        df_csv = df_csv.reset_index(drop=True)\n",
    "        # print(df_csv[df_csv['file_name']=='a01_sykkel.wav'])\n",
    "        \n",
    "        if len(df_csv.model_name.unique()) > 1:\n",
    "            print(f\"Error: {path} has more than one model name\")\n",
    "            break\n",
    "        \n",
    "        # Add ID column\n",
    "        df_csv[\"id\"] = df_csv[\"file_name\"].apply(lambda x: x.split('_')[0])\n",
    "        df_csv = df_csv.sort_values(by=['id'])\n",
    "        \n",
    "        # print(df_csv.columns)    \n",
    "        # Reorder column names\n",
    "        reorder_column = [\"id\", \"global_score\", \n",
    "                        \"target_word\", \"PER\", \n",
    "                        \"transcribed_word\", \"CER\", \n",
    "                        \"transcribed_word_striped\", \"striped_CER\",\n",
    "                        \"file_name\", \"model_name\"]\n",
    "        \n",
    "        df_csv = df_csv[reorder_column]\n",
    "        # print(df_csv.columns)   \n",
    "\n",
    "        if bool:\n",
    "            # Save the file\n",
    "            csv_name = path.split('/')[-1]\n",
    "            df_csv.to_csv(os.path.join(results_dir, csv_name), index=False)    \n",
    "\n",
    "# resave_transcription_df(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#FF6F91\"> BOX PLOT &nbsp;:&nbsp; </span>**\n",
    "#### <span style=\"color:#ebaed8\">  Every *model* compared &nbsp;:&nbsp; CER vs. PER for <b>Native</b>, <b>Non Native</b> and <b>All</b> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directory to save the box plots &nbsp; : &nbsp; <span style=\"color:#ebaed8\"> *./BoxPlots/Model_CER*</i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_box_cer = './Transcriptions/Results/BoxPlots/Model_CER'\n",
    "if not os.path.exists(save_dir_box_cer):\n",
    "    os.makedirs(save_dir_box_cer)\n",
    "    print(f\"Directory {save_dir_box_cer} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a fuction that works for both all, native and non-native speakers\n",
    "\n",
    "##### **<span style=\"color:#FF9671\"> Giga Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also use \"lst_csv\", but safer to remake the list\n",
    "lst_csv_re_saved = os.listdir(results_dir)\n",
    "lst_csv_re_saved = [file for file in lst_csv_re_saved if file.startswith('tran') & file.endswith('v1.csv')] \n",
    "lst_csv_re_saved = sorted(lst_csv_re_saved, key=lambda x: test_for_models.index(x.split('_')[-2]))\n",
    "lst_path = [os.path.join(results_dir, file) for file in lst_csv_re_saved] \n",
    "ggm = pd.DataFrame()\n",
    "# Iterate through the CSV files to add what is missing\n",
    "for path in lst_path:\n",
    "    # print(f\"Reading {path}\")\n",
    "    df_csv = pd.read_csv(path)\n",
    "    ggm = pd.concat([ggm, df_csv], ignore_index=True)\n",
    "ggm = ggm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<span style=\"color:#FFC75F\"> Fix model names for Giga Matrix**\n",
    "Fix what the model names in the box plot shows, and that the PER can be one of the boxes in teh box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_model_names(gigamind:pd.DataFrame, cer_value:str = 'CER'):\n",
    "    # Remove \"whisper\" from the model name\n",
    "    gigamind['model_name'] = gigamind['model_name'].apply(lambda x: x.replace('nb-whisper', 'NNL'))\n",
    "\n",
    "    # Get Capitalized model names fro tiny, base and medium\n",
    "    gigamind['model_name'] = gigamind['model_name'].apply(lambda x: x.capitalize() if not x.startswith('NNL') or x.startswith('P') else x)\n",
    "\n",
    "    # Add PER to model names so it gets its own column\n",
    "    new_per = gigamind[gigamind.model_name == 'Tiny'][['PER', 'file_name']].copy()\n",
    "    new_per = new_per.rename(columns={\"PER\": f\"{cer_value}\"})\n",
    "    new_per['model_name'] = 'Phone Error Rate (PER)'\n",
    "\n",
    "    gigamind = pd.concat([new_per, gigamind], ignore_index=True)\n",
    "    return gigamind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<span style=\"color:#F9F871\"> BOX PLOT function for all models comparing PER and CER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plots_model(giga_df:pd.DataFrame, save_dir:str, title:str, cer_value:str = 'CER', cer_name:str = 'CER' , exstended:int=2.1, max_verbatim:int = 1.5):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    # ---------- Color palette  ---------- #\n",
    "    palette = ['#FFC75F', # PER color\n",
    "        '#A8BB5C', '#20887A', '#2F4858', # Model colors       \n",
    "        '#A8BB5C', '#20887A', '#2F4858',          \n",
    "        '#A8BB5C', '#20887A', '#2F4858'\n",
    "        ]\n",
    "    \n",
    "    # ---------- Horizontal lines ---------- #\n",
    "    # Line for the maximum cer_value for the medium-verbaitm\n",
    "    max_cer_model1 = giga_df[(giga_df['model_name'] == 'NNL-medium-verbatim') & \n",
    "                            (giga_df[cer_value] >= 0) & \n",
    "                            (giga_df[cer_value] <= max_verbatim)][cer_value].max()\n",
    "    ax.axhline(max_cer_model1, color='#B5AA99', linestyle='--')\n",
    "    \n",
    "    # Line for the median value\n",
    "    median_value = giga_df[giga_df['model_name'] == 'Phone Error Rate (PER)'][cer_value].median()\n",
    "    ax.axhline(median_value, color='#C1554D', linestyle='--')\n",
    "    \n",
    "    # Add to make space for the legend\n",
    "    ax.axhline(exstended, color='#ffffff', linestyle='--')\n",
    "    \n",
    "    #  ----------  Boxplot ---------- #\n",
    "    sns.boxplot(x='model_name', y=cer_value, hue='model_name', data=giga_df, ax=ax, showfliers=False, palette=palette)\n",
    "\n",
    "    #  ---------- Model legend box  ---------- #  (Custom legends found by ChatGPT) \n",
    "    chosen_colors = ['#A8BB5C', '#20887A', '#2F4858']\n",
    "    chosen_names = ['OpenAI', 'Norwegian National Library (NNL)', 'NNL-Verbatim']\n",
    "    legend_patches = [mpatches.Patch(color=color, label=name) for name, color in zip(chosen_names, chosen_colors)]\n",
    "\n",
    "    # Add legend with custom settings\n",
    "    legend = ax.legend(handles=legend_patches, loc='upper right', frameon=True, shadow=True, title='Models')\n",
    "    legend.get_frame().set_facecolor('#f0eeeb')  # Background color\n",
    "    legend.get_title().set_fontsize('12')  # Title font size\n",
    "    for text in legend.get_texts():\n",
    "        text.set_fontsize('11')  # Legend text font size\n",
    "    \n",
    "    #  ---------- Title and labels ---------- #\n",
    "    plt.title(f'PER for the target words compared to the {cer_name} for the different models - {title}', fontsize=17)\n",
    "    plt.xlabel('Target words  &  Model names', fontsize=14)\n",
    "    plt.ylabel(f'PER & {cer_name}', fontsize=14)\n",
    "    \n",
    "    #  ---------- Wrap x-axis ---------- # (Wrap method found by ChatGPT) \n",
    "    model_names = [ '\\n'.join(wrap(label, 14)) for label in giga_df['model_name'].unique() ]\n",
    "    plt.xticks(ticks=range(len(model_names)), labels=model_names)\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir)\n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b><span style=\"color:#D65DB1\"> Box plot for all models, all data, native and non-native</span></b> NOT STRIPED (NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ All data Box Plot ------------ #\n",
    "ggm_fix = fix_model_names(ggm)\n",
    "box_plots_model(ggm_fix, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_All_Data_NS.png'), 'Whole dataset')\n",
    "\n",
    "# -------------- Non-Native Box Plot -------------- #\n",
    "ggm_d = ggm[ggm['id'].str.contains('d')].copy()\n",
    "ggm_fix_non_native = fix_model_names(ggm_d)\n",
    "box_plots_model(ggm_fix_non_native, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_Native_NS.png'), \n",
    "                            title='Native dataset', exstended = 2.2, max_verbatim = 1)\n",
    "\n",
    "# -------------- Non Native Box Plot -------------- #\n",
    "ggm_a = ggm[ggm['id'].str.contains('a')].copy()\n",
    "ggm_fix_native = fix_model_names(ggm_a)\n",
    "box_plots_model(ggm_fix_native, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_Non_Native_Data_NS.png'), \n",
    "                            title='Non Native dataset', exstended = 2.05, max_verbatim = 1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b><span style=\"color:#FF6F91\"> Box plot for all models, all data, native and non-native</span></b> STRIPED (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ All data Box Plot ------------ #\n",
    "ggm_fix = fix_model_names(ggm, cer_value='striped_CER')\n",
    "box_plots_model(ggm_fix, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_All_Data_S.png'), \n",
    "                            title = 'Whole dataset', cer_value = 'striped_CER', cer_name = 'Striped CER',\n",
    "                            exstended = 2, max_verbatim = 1.4)\n",
    "\n",
    "\n",
    "# -------------- Native Box Plot -------------- #\n",
    "ggm_d = ggm[ggm['id'].str.contains('d')].copy()\n",
    "ggm_fix_native = fix_model_names(ggm_d, cer_value='striped_CER')\n",
    "box_plots_model(ggm_fix_native, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_Native_Data_S.png'), \n",
    "                            title='Native dataset', exstended = 2.2, max_verbatim = 1,\n",
    "                            cer_value = 'striped_CER', cer_name = 'striped CER')\n",
    "\n",
    "# -------------- Non-Native Box Plot -------------- #\n",
    "ggm_a = ggm[ggm['id'].str.contains('a')].copy()\n",
    "ggm_fix_non_native = fix_model_names(ggm_a, cer_value='striped_CER')\n",
    "box_plots_model(ggm_fix_non_native, os.path.join(save_dir_box_cer, 'PER_&_CER_All_Models_Non_Native_S.png'), \n",
    "                            title='Non Native dataset', exstended = 2.1, max_verbatim = 1.6,\n",
    "                            cer_value = 'striped_CER', cer_name = 'striped CER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#845EC2\">845EC2</span></b>\n",
    "<b><span style=\"color:#D65DB1\">D65DB1</span></b>\n",
    "<b><span style=\"color:#FF6F91\">FF6F91</span></b>\n",
    "<b><span style=\"color:#FF9671\">FF9671</span></b>\n",
    "<b><span style=\"color:#FFC75F\">FFC75F</span></b>\n",
    "<b><span style=\"color:#F9F871\">F9F871</span></b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#FFC75F\">  Every **ID** compared for best model &nbsp;:&nbsp; CER vs. PER for <b>Native</b>, <b>Non Native</b> and <b>all</b> </span>\n",
    "Create directory to save the box plots &nbsp; : &nbsp; <span style=\"color:#F9F871\"> *./BoxPlots/Model_CER*</i></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<span style=\"color:#FF6F91\"> BOX PLOT function for all ID's comparing PER and CER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plots_id(best_model:pd.DataFrame, save_dir:str, cer_value:str = 'CER', cer_name:str = 'CER'):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    # df_melted = pd.melt( ccccccccccc, id_vars=['id'], value_vars=['PER', cer_value]) \n",
    "    # df_melted_a = df_melted[df_melted['id'].str.contains('a')].copy() # Non Native\n",
    "    # df_melted_d = df_melted[df_melted['id'].str.contains('d')].copy() # Native \n",
    "    \n",
    "    # #  ----------  Boxplot ---------- #\n",
    "    # sns.boxplot(x='id', y=cer_value, hue='id', data=df_melted_a, ax=ax, showfliers=False, palette=['#FFC75F', '#FF6F91'])\n",
    "    # sns.boxplot(x='id', y=cer_value, hue='id', data=df_melted_d, ax=ax, showfliers=False, palette=['#FFC75F', '#FF9671'])\n",
    "    \n",
    "    # #  ---------- Title and labels ---------- #\n",
    "    # plt.title(f\"PER ofr the target words compared to the {cer_name} for the different ID's\", fontsize=17)\n",
    "    # plt.xlabel(\"PER Target words &  CER ID's\", fontsize=14)\n",
    "    # plt.ylabel(f'PER & {cer_name}', fontsize=14)\n",
    "    \n",
    "    # #  ---------- x- and y-axis ---------- #\n",
    "    # plt.xticks(fontsize=13)\n",
    "    # plt.yticks(fontsize=13)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # # plt.savefig(save_dir)\n",
    "    # # plt.close()\n",
    "    # plt.show()\n",
    "    \n",
    "# -------- BEST MODEL -------- #\n",
    "df_best = pd.read_csv(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b><span style=\"color:#ffdb9f\"> Box plot for all id's and all data</span></b> NOT STRIPED (NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plots_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b><span style=\"color:#ff9ab2\"> Box plot for all id's and all data</span></b> STRIPED (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
