{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Emty Transcriptions from Trascribed Data Frame\n",
    "\n",
    "For some reason does some of the emty trascriptions sneek into the trascribed dataframe. This script fixes this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this scripts task is to go throng all the transcribed files. \n",
    "# It checks if there are any missing values in the transcribed files, that is not in the empty transcriptions file.\n",
    "# It also compar the length to teh assessment files, and assume theses row are all files the model could not transcribe\n",
    "# They are therefor deemed as empty transcriptions, and given CER = 1.0\n",
    "import self_made_functions as smf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the transcribed files, the assessment df, and Initiate the empty list to store the fixed transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transcribed files to look through\n",
    "path_transcriptions = './Transcriptions'\n",
    "lst = os.listdir(path_transcriptions)\n",
    "lst = [file for file in lst if file.startswith('tran') and file.endswith('.csv')]\n",
    "\n",
    "# Compar with original assessment\n",
    "df_assessment, _ = smf.get_correct_df()\n",
    "\n",
    "# Initialize the empty transcriptions data frame\n",
    "empty_transcriptions = pd.DataFrame(columns=[\"file_name\",\n",
    "                                \"CER\",  # Character Error Rate (CER)\n",
    "                                \"target_word\", \n",
    "                                \"global_score\",\n",
    "                                'model_name', 'version'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate throng all the transcriptions and find missing values. Remove these from the transcribed data frame, and save them accordantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n"
     ]
    }
   ],
   "source": [
    "for file in lst:\n",
    "    df_csv = pd.read_csv(os.path.join(path_transcriptions, file))\n",
    "    nan_df = df_csv[df_csv.isna('Transcribed').any(axis=1)]\n",
    "    \n",
    "    if not nan_df.empty:\n",
    "        print(f'NaN in {file}')\n",
    "        df_csv = df_csv.dropna()\n",
    "        df_csv.to_csv(os.path.join(path_transcriptions, file), index=False)\n",
    "    else:\n",
    "        print(f'No NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there is non nan values in the transcribed data frame. Meaning all missing rows in the assessment data frame are empty transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1518214/2080126791.py:49: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  empty_transcriptions = pd.concat([empty_transcriptions, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "6 6\n",
      "False og len: 9322 csv len: 9218 diff: 104\n",
      "110 107\n",
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "116 109\n",
      "False og len: 9322 csv len: 9319 diff: 3\n",
      "119 109\n",
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "125 110\n",
      "False og len: 9322 csv len: 9319 diff: 3\n",
      "128 110\n",
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "134 112\n",
      "False og len: 9322 csv len: 9282 diff: 40\n",
      "174 132\n",
      "False og len: 9322 csv len: 9295 diff: 27\n",
      "201 146\n",
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "207 146\n",
      "False og len: 9322 csv len: 9218 diff: 104\n",
      "311 146\n",
      "False og len: 9322 csv len: 9316 diff: 6\n",
      "317 146\n"
     ]
    }
   ],
   "source": [
    "# Iterate throng all the transcriptions and find the missing values\n",
    "for file in lst:\n",
    "    df_csv = pd.read_csv(os.path.join(path_transcriptions, file))\n",
    "    model = file.split('_')[1]\n",
    "    version = file.split('_')[2].split('.')[0]\n",
    "    \n",
    "    # Look for rows in the transcription whit NaN values, \n",
    "    # and rows in the assessment that is not in the transcription\n",
    "\n",
    "    missing_rows = df_assessment[~df_assessment['File name'].isin(df_csv['File name'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # I assume this theses row are all files the model could not transcribe\n",
    "    # They are deemed as empty transcriptions, and given CER = 1.0\n",
    "    # Check if the missing values are already in the empty transcriptions file\n",
    "    \n",
    "    # Handle the missing rows\n",
    "    for i, row in missing_rows.iterrows():\n",
    "        new_row = {\"file_name\": row['File name'],\n",
    "                    \"CER\": 1.0,  # Character Error Rate (CER)\n",
    "                    \"target_word\": row['Word'], \n",
    "                    \"global_score\": row['Score'],\n",
    "                    'model_name': model,\n",
    "                    'version': version}\n",
    "        new_row = pd.DataFrame(new_row, index=[0])\n",
    "        empty_transcriptions = pd.concat([empty_transcriptions, new_row], ignore_index=True)\n",
    "    \n",
    "    # handel the NaN / missing values\n",
    "    for i, row in nan_df.iterrows():\n",
    "        new_row = {\"file_name\": row['File name'],\n",
    "                    \"CER\": 1.0,  # Character Error Rate (CER)\n",
    "                    \"target_word\": row['Word'], \n",
    "                    \"global_score\": row['OG Score'],\n",
    "                    'model_name': model,\n",
    "                    'version': version}\n",
    "        new_row = pd.DataFrame(new_row, index=[0])\n",
    "        empty_transcriptions = pd.concat([empty_transcriptions, new_row], ignore_index=True)\n",
    "\n",
    "    bool = missing_rows['File name'].isin(nan_df['File name']).any() # Se if the nan values are in the missing rows\n",
    "    if bool:\n",
    "        print('Some of the missing values are in the missing rows\\n Make script for this')\n",
    "        break\n",
    "    else:\n",
    "        # remove the nan values from the transcription file\n",
    "        df_csv_no_nan = df_csv.dropna()\n",
    "        if len(df_csv) != len(df_csv_no_nan):\n",
    "            # print(f'NaN gets droped from {file}')\n",
    "            df_csv_no_nan.to_csv(os.path.join(path_transcriptions, file), index=False)\n",
    "            df_csv =df_csv_no_nan\n",
    "        # else: \n",
    "            # print(f'No NaN values in {file}')\n",
    "            \n",
    "    print(len(df_assessment) == len(df_csv), 'og len:', len(df_assessment), 'csv len:', len(df_csv), 'diff:', len(df_assessment)-len(df_csv))\n",
    "    print(len(empty_transcriptions), len(empty_transcriptions.drop_duplicates('file_name')))\n",
    "    \n",
    "# Save the empty transcriptions\n",
    "# for version in empty_transcriptions.version.unique():\n",
    "#     empty_version = empty_transcriptions[empty_transcriptions['version'] == version]\n",
    "#     empty_version = empty_version.drop(columns=['version'])\n",
    "#     empty_version.to_csv(os.path.join(path_transcriptions, f'empty_transcription_{version}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>CER</th>\n",
       "      <th>target_word</th>\n",
       "      <th>global_score</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a12_graa.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>grå</td>\n",
       "      <td>2</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d09_svart.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>svart</td>\n",
       "      <td>1</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d10_svart.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>svart</td>\n",
       "      <td>2</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a29_lun.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lun</td>\n",
       "      <td>4</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a22_mur.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mur</td>\n",
       "      <td>5</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a21_gul.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gul</td>\n",
       "      <td>4</td>\n",
       "      <td>nb-whisper-tiny-verbatim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  CER target_word global_score                model_name\n",
       "0   a12_graa.wav  1.0         grå            2  nb-whisper-tiny-verbatim\n",
       "1  d09_svart.wav  1.0       svart            1  nb-whisper-tiny-verbatim\n",
       "2  d10_svart.wav  1.0       svart            2  nb-whisper-tiny-verbatim\n",
       "3    a29_lun.wav  1.0         lun            4  nb-whisper-tiny-verbatim\n",
       "4    a22_mur.wav  1.0         mur            5  nb-whisper-tiny-verbatim\n",
       "5    a21_gul.wav  1.0         gul            4  nb-whisper-tiny-verbatim"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    empty_transcriptions\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(model, version)\n",
    "    # print(nan_df['File name'].values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        new_empty_rows = new_empty_rows.drop(['Prosody','Noise/Disruption','Pre-speech noise','Repetition', 'Assessor', 'Pronunciation'], axis=1)\n",
    "        leaf_row = leaf_row.drop(['Prosody','Noise/Disruption','Pre-speech noise','Repetition', 'Assessor', 'Pronunciation'], axis=1)\n",
    "        \n",
    "        # Calulate PER and add CER = 1.0\n",
    "        new_empty_rows['per'] =  new_empty_rows.apply(lambda x: x['pronScores'].split(' ').count('0')/len(x['pronScores'].split(' ')), axis=1)\n",
    "        leaf_row['per'] =  leaf_row.apply(lambda x: x['pronScores'].split(' ').count('0')/len(x['pronScores'].split(' ')), axis=1)\n",
    "        \n",
    "        new_empty_rows['CER'] = 1.0\n",
    "        leaf_row['CER'] = 1.0\n",
    "        \n",
    "        empty_rows = new_empty_rows.drop(['pronScores'], axis=1)\n",
    "        leaf_row = leaf_row.drop(['pronScores'], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                \n",
    "            # The following prints show the model has more empty transcription. \n",
    "            # After this should df == df_original.\n",
    "            print(model)\n",
    "            print(len(df), len(df_original))\n",
    "            if len(df) != len(df_original):\n",
    "                print('Bruh')\n",
    "                missing_rows = df_original[~df_original['File name'].isin(df['File name'])]\n",
    "                print(len(missing_rows), missing_rows['File name'].values)\n",
    "                for idx, row in missing_rows.iterrows():\n",
    "                    new_row = {\n",
    "                        'File name': row['File name'],\n",
    "                        'OG word': row['Word'],\n",
    "                        'idx': idx,\n",
    "                        'Model': model\n",
    "                    }\n",
    "                    rows.append(new_row)\n",
    "                                \n",
    "                    # df.to_csv(df_path, index=False)\n",
    "                    # print(f'Updated original df saved to {df_path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for model in models:\n",
    "            file_name = df_base + model + '_' + file_version + '.csv'\n",
    "            df_path = os.path.join(df_dir, file_name)\n",
    "            df = pd.read_csv(df_path)\n",
    "            \n",
    "            # PART 3: Check for missing values in the transcription file\n",
    "            nan_df = df[df.isna().any(axis=1)]\n",
    "            if not nan_df.empty:\n",
    "                print(f'Model: {model}, Version: {file_version}')\n",
    "                # print('The missing values in the Transcribed file:\\n', nan_df, '\\n')\n",
    "                \n",
    "                # Check if the missing values are already in the empty transcriptions file\n",
    "                if not nan_df['File name'].isin(mt_df['File name']).any():\n",
    "                    print('The missing values are not in the empty transcriptions file\\n')\n",
    "                    \n",
    "                    # PART 4: Add the missing values to the empty transcriptions file\n",
    "                    rows = []\n",
    "                    for idx, row in nan_df.iterrows():\n",
    "                        new_row = {\n",
    "                            'File name': row['File name'],\n",
    "                            'OG word': row['Word'],\n",
    "                            'idx': idx,\n",
    "                            'Model': model\n",
    "                        }\n",
    "                        rows.append(new_row)\n",
    "                    \n",
    "                    new_mt_df = pd.DataFrame(rows)\n",
    "                    # print('Rows to be added to the new dataframe:\\n', new_mt_df, '\\n')\n",
    "                    \n",
    "                    # Update the mt_df and save it\n",
    "                    finito_mt_df = pd.concat([mt_df, new_mt_df], ignore_index=True)\n",
    "                    finito_mt_df.to_csv(mt_path, index=False)\n",
    "                    # print('Updated empty df:\\n', finito_mt_df[finito_mt_df['Model'] == model], '\\n')\n",
    "                    \n",
    "                    # PART 5: Remove the rows with missing values from the original dataframe\n",
    "                    df = df.dropna()            \n",
    "            else: \n",
    "                print('The missing values are already in the empty transcriptions file\\n')\n",
    "                \n",
    "                \n",
    "            # The following prints show the model has more empty transcription. \n",
    "            # After this should df == df_original.\n",
    "            print(model)\n",
    "            print(len(df), len(df_original))\n",
    "            if len(df) != len(df_original):\n",
    "                print('Bruh')\n",
    "                missing_rows = df_original[~df_original['File name'].isin(df['File name'])]\n",
    "                print(len(missing_rows), missing_rows['File name'].values)\n",
    "                for idx, row in missing_rows.iterrows():\n",
    "                    new_row = {\n",
    "                        'File name': row['File name'],\n",
    "                        'OG word': row['Word'],\n",
    "                        'idx': idx,\n",
    "                        'Model': model\n",
    "                    }\n",
    "                    rows.append(new_row)\n",
    "                                \n",
    "                    # df.to_csv(df_path, index=False)\n",
    "                    # print(f'Updated original df saved to {df_path}\\n')\n",
    "\n",
    "\n",
    "print('Process completed successfully.')\n",
    "\n",
    "# PART 6: Save the updated empty transcriptions file\n",
    "# (Already saved within the loop above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "# PART 1: Load the data -----------------------------------------------------------------\n",
    "directory = './Transcriptions'\n",
    "df_file_name = 'transcriptions_nb-whisper-medium-verbatim_v1.csv'\n",
    "path = os.path.join(directory, df_file_name)\n",
    "\n",
    "model_name = df_file_name.split('_')[1]\n",
    "version = df_file_name.split('_')[2].split('.')[0]\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# PART 2: Check for missing values -------------------------------------------------------\n",
    "nan_df = df[df.isna().any(axis=1)] # find rows that is nan\n",
    "print('The missing values in the Trascriped file:\\n', nan_df, '\\n')\n",
    "\n",
    "# PART 3: Check if the missing values are in the empty transcriptions file ----------------\n",
    "# Find if the Emty rows in the dataframe is alreaddy added in the emty transcriptions file\n",
    "mt_file_name = 'empty_transcription_v2.csv'\n",
    "mt_path = os.path.join(directory, mt_file_name)\n",
    "\n",
    "mt_df = pd.read_csv(mt_path)\n",
    "\n",
    "# Check if the mt df conatins the mt transcriptions \n",
    "print('Current rows in the emty dataframe:\\n', mt_df[mt_df['Model'] == model_name], '\\n')\n",
    "\n",
    "# If they are not in the file, add them to the file\n",
    "\n",
    "if nan_df['File name'].values not in mt_df['File name'].values:\n",
    "    print('The missing values are not in the empty transcriptions file\\n')\n",
    "    \n",
    "\n",
    "    # PART 4: Add the missing values to the empty transcriptions file --------------------------\n",
    "    # Find the relevant info in the mt datafram\n",
    "    file_name = nan_df['File name'].values\n",
    "    OG_word = nan_df['Word'].values\n",
    "    idx = nan_df.index.values\n",
    "    model_name = model_name\n",
    "\n",
    "    # Add the new information to the mt dataframe\n",
    "    new_mt_df = {\n",
    "            'File name': row['File name'],\n",
    "            'OG word': row['Word'],\n",
    "            'idx' : idx,\n",
    "            'Model': model_name\n",
    "        }\n",
    "\n",
    "    new_mt_df = pd.DataFrame(new_mt_df)\n",
    "    print('Rows to the new dataframe:\\n', new_mt_df, '\\n')\n",
    "\n",
    "    # Utpdate the mt_df to be correct og save it\n",
    "    finito_mt_df = pd.concat([mt_df, new_mt_df], ignore_index=True)\n",
    "    print('finito empty df:\\n', finito_mt_df[finito_mt_df['Model'] == model_name], '\\n')\n",
    "\n",
    "# PART 5: remove the rows from the original dataframe and save it --------------------------\n",
    "df = df.dropna()\n",
    "# df.to_csv(path, index=False)\n",
    "\n",
    "# PART 6: Save the updated empty transcriptions file ---------------------------------------\n",
    "# finito_mt_df.to_csv(mt_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# PART 1: Define directories and base filenames\n",
    "mt_dir = './Transcriptions/Empty_Transcriptions/Wrong'\n",
    "df_dir = './Transcriptions'\n",
    "df_base = 'transcriptions_'\n",
    "\n",
    "# PART 2: Iterate through empty transcription files\n",
    "for file in os.listdir(mt_dir):\n",
    "    if file.startswith('empty') and file.endswith('.csv'):\n",
    "        file_version = file.split('_')[2].split('.')[0]\n",
    "        mt_path = os.path.join(mt_dir, file)\n",
    "        mt_df = pd.read_csv(mt_path)\n",
    "        \n",
    "        models = mt_df['Model'].unique()\n",
    "        \n",
    "        for model in models:\n",
    "            file_name = df_base + model + '_' + file_version + '.csv'\n",
    "            df_path = os.path.join(df_dir, file_name)\n",
    "            df = pd.read_csv(df_path)\n",
    "            \n",
    "            # PART 3: Check for missing values in the transcription file\n",
    "            nan_df = df[df.isna().any(axis=1)]\n",
    "            if not nan_df.empty:\n",
    "                print(f'Model: {model}, Version: {file_version}')\n",
    "                # print('The missing values in the Transcribed file:\\n', nan_df, '\\n')\n",
    "                \n",
    "                # Check if the missing values are already in the empty transcriptions file\n",
    "                if not nan_df['File name'].isin(mt_df['File name']).any():\n",
    "                    print('The missing values are not in the empty transcriptions file\\n')\n",
    "                    \n",
    "                    # PART 4: Add the missing values to the empty transcriptions file\n",
    "                    rows = []\n",
    "                    for idx, row in nan_df.iterrows():\n",
    "                        new_row = {\n",
    "                            'File name': row['File name'],\n",
    "                            'OG word': row['Word'],\n",
    "                            'idx': idx,\n",
    "                            'Model': model\n",
    "                        }\n",
    "                        rows.append(new_row)\n",
    "                    \n",
    "                    new_mt_df = pd.DataFrame(rows)\n",
    "                    # print('Rows to be added to the new dataframe:\\n', new_mt_df, '\\n')\n",
    "                    \n",
    "                    # Update the mt_df and save it\n",
    "                    finito_mt_df = pd.concat([mt_df, new_mt_df], ignore_index=True)\n",
    "                    finito_mt_df.to_csv(mt_path, index=False)\n",
    "                    # print('Updated empty df:\\n', finito_mt_df[finito_mt_df['Model'] == model], '\\n')\n",
    "                    \n",
    "                    # PART 5: Remove the rows with missing values from the original dataframe\n",
    "                    df = df.dropna()\n",
    "                    df.to_csv(df_path, index=False)\n",
    "                    # print(f'Updated original df saved to {df_path}\\n')\n",
    "            else: \n",
    "                print('The missing values are already in the empty transcriptions file\\n')\n",
    "\n",
    "print('Process completed successfully.')\n",
    "\n",
    "# PART 6: Save the updated empty transcriptions file\n",
    "# (Already saved within the loop above)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
