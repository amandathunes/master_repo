{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style=\"color:#ADF88B\">Fix Concatenation Results</span></b>\n",
    "\n",
    "Script to fix the concatenated result data frame. I recreate excatly how the audio files are concatenated, and exstracting the target words, target PER, target WER and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys      \n",
    "script_directory = '../'\n",
    "sys.path.append(script_directory)\n",
    "import self_made_functions as smf\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_audio(df:pd.DataFrame, s:int=0, e:int=10, name = ''):\n",
    "    concat_rows = df.iloc[s:e]  # Rows to concatenate\n",
    "    input_lst = list(concat_rows.Word.values) # get input string\n",
    "\n",
    "    target_wer_count = 0\n",
    "    pron_lst = [] # list of pron scores to calcualte CER\n",
    "    \n",
    "    for row in concat_rows.itertuples():\n",
    "        per_score = (row.pronScores.count('1')/len(row.pronScores.split(' ')))\n",
    "        pron_lst.append(row.pronScores)\n",
    "        if per_score != 0:\n",
    "            target_wer_count += 1   \n",
    "    \n",
    "    target_wer = target_wer_count/len(input_lst) # Correct Word Error Rate (WER)\n",
    "    \n",
    "    pron_lst = (' '.join(pron_lst)) # String of all the 0 adn 1s\n",
    "    target_per = pron_lst.count('1')/len(pron_lst) # Correct Character Error Rate (CER)\n",
    "\n",
    "    audio_name = name + f'words_{s}_{e}.wav'\n",
    "    return target_per, target_wer, input_lst, audio_name\n",
    "\n",
    "# Later I can go thorug the transcriptions and se that they are properly stripped, and calculated CER and WER\n",
    "def modify_transcriptions(df_csv:pd.DataFrame):\n",
    "    df_csv['transcribed_word_striped'] = df_csv['Transcribed'].apply(\n",
    "    lambda x: x.strip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\") \n",
    "    if isinstance(x, str) else x)      \n",
    "    df_csv['striped_CER'] = df_csv.apply(lambda x: jiwer.cer(x['Word'], x['transcribed_word_striped']), axis=1)\n",
    "    return df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assessment, _ = smf.get_correct_df()\n",
    "df_assessment['id'] = df_assessment['File name'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "# Test 1 :  Grouping by score. Sorted by speaker.\n",
    "df_test_1 = df_assessment.sort_values(by=['id'], ascending=False) # Sorted by ID\n",
    "df_test_1 = df_test_1.reset_index(drop=True)\n",
    "df_test_1 = df_test_1.groupby('Score')# Grouped by score\n",
    "df_test_1_name = 'scores_id_sorted'\n",
    "\n",
    "# Test 2 :  Grouping by score. Random speakers.\n",
    "df_test_2 = df_assessment.sample(frac=1).reset_index(drop=True)\n",
    "df_test_2 = df_test_2.groupby('Score')\n",
    "df_test_2_name = 'scores_id_mixed'\n",
    "\n",
    "# Test 3 :  Grouping by speaker. No sorting.\n",
    "df_test_3 = df_assessment.groupby('id')# Grouped by speaker\n",
    "df_test_3_name = 'group_id_sorted_score'\n",
    "\n",
    "# Test 4 :  No group. Everything in random order.\n",
    "df_test_4 = df_assessment.sample(frac=1).reset_index(drop=True)\n",
    "df_test_4_name = 'no_group_mixed'\n",
    "\n",
    "# --------- Store Information ------------ #\n",
    "halo_df = pd.DataFrame(columns=['PER', \n",
    "                                'WER', \n",
    "                                'input_words_list', \n",
    "                                'audio_name', \n",
    "                                'test_name',\n",
    "                                'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3599180/3318079430.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  halo_df = pd.concat([halo_df, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : Grouping by score. Sorted by speaker.\n",
    "for idx, score_group in df_test_1:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, wer, input_lst, audio_name = concat_audio(score_group, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_1_name,\n",
    "                'test' : 1} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 : Grouping by score. Random speakers.\n",
    "for idx, score_group in df_test_2:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(score_group, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_2_name,\n",
    "                'test' : 2} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 : Grouping by speaker. No sorting.\n",
    "for idx, person in df_test_3:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        speaker_id = person.iloc[0]['id']\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(score_group, s, e, name=f'{speaker_id}_')\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_3_name,\n",
    "                'test' : 3} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4 : No group. Everything in random order.\n",
    "for i in range(0, len(df_test_4)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(df_test_4, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_4_name,\n",
    "                'test' : 4} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the current information CSV files\n",
    "\n",
    "1) ~~Load the transcribed CSV~~\n",
    "2) ~~Check that all the audio_names and input_words_list match~~\n",
    "3) ~~Add the correct information to the CSV~~\n",
    "4) Strip the transcriptions properly\n",
    "5) ~~Fix update CER and WER~~\n",
    "6) ~~Create a new file with the correct information~~\n",
    "7) Check no transcriptions has NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_id                  0\n",
       "score                       0\n",
       "input_string                0\n",
       "translated_string           3\n",
       "translated_CER            104\n",
       "translated_WER            104\n",
       "target_CER                  0\n",
       "target_CER_sum              0\n",
       "target_WER                  0\n",
       "length_deviation_words      0\n",
       "audio_name                  0\n",
       "audio_path                  0\n",
       "trans_CER                   0\n",
       "trans_WER                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='../3x10_Concatenation_information/nb-whisper-base-verbatim__concatenated_audio_information_group_id_sorted_score_v1.csv'\n",
    "check_df = pd.read_csv(file_name)\n",
    "\n",
    "check_df.isna().sum()   \n",
    "# check_df['translated_string'].isna().sum()   \n",
    "# NB! Ignore translated_CER, translated_WER. They are suposed to be NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 3 NaN values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_group_id_sorted_score_v1.csv.\n",
      "Error: 1 NaN values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_no_group_mixed_v1.csv.\n",
      "Error: 2 NaN values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_scores_id_sorted_v1.csv.\n",
      "Error: 1 NaN values in the translated_string column for file nb-whisper-medium__concatenated_audio_information_scores_id_mixed_v1.csv.\n",
      "Error: 1 NaN values in the translated_string column for file nb-whisper-medium-verbatim__concatenated_audio_information_scores_id_mixed_v1.csv.\n"
     ]
    }
   ],
   "source": [
    "file_lst = os.listdir('../3x10_Concatenation_information')\n",
    "\n",
    "for file in file_lst:\n",
    "    # print(f'Working on file: {file}')\n",
    "    # ----- Step 1 : Load the data ----- #\n",
    "    df = pd.read_csv(f'../3x10_Concatenation_information/{file}')\n",
    "    get_test = file.split('_information_')[1].split('_v1')[0]\n",
    "    \n",
    "    df = df.rename(columns={'target_CER': 'PER', 'target_WER': 'WER'})\n",
    "    \n",
    "    # ----- Step 1.1 : Check for NaN values ----- #\n",
    "    nan = df['translated_string'].isna().sum()   \n",
    "    if nan > 0:\n",
    "        print(f'Error: {nan} NaN values in the translated_string column for file {file}.')  \n",
    "    \n",
    "    # ----- Step 2 & 3 : Merge the data ----- #\n",
    "    same_df_split = halo_df[(halo_df['test_name'] == get_test) & \n",
    "                        (halo_df['audio_name'].isin(df['audio_name']))]\n",
    "    if not len(same_df_split) == len(df):\n",
    "        print(f'Error: Length of split data frames does not match for file {file}.\\n{len(same_df_split)} vs {len(df)}')\n",
    "    \n",
    "    # Merging df with same_df_split on the 'audio_name' column\n",
    "    merged_df = df.merge(same_df_split[['audio_name', 'PER', 'WER']], on='audio_name', how='left', suffixes=('', '_new'))\n",
    "\n",
    "    # Updating the 'PER' column in df with the values from the merged DataFrame\n",
    "    df['PER'] = merged_df['PER_new']\n",
    "    df['WER'] = merged_df['WER_new']\n",
    "    \n",
    "    # Check for nans to ensure smooth merge\n",
    "    if df['PER'].isnull().values.any():\n",
    "        print(f'Error: NaN values in the PER column for file {file}.')\n",
    "    elif df['WER'].isnull().values.any():\n",
    "        print(f'Error: NaN values in the WER column for file {file}.')\n",
    "        \n",
    "    # ----- Step 4 : Strip the transcriptions ----- #\n",
    "    df['translated_string'] = df['translated_string'].apply(lambda x: x.strip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\") \n",
    "        if isinstance(x, str) else x)\n",
    "    \n",
    "    # ----- Step 5 : Calculate the CER & WER ----- #\n",
    "    if nan == 0:\n",
    "        df['translated_WER'] = df.apply(lambda x: jiwer.wer(x['input_string'], x['translated_string']), axis=1)\n",
    "        df['translated_CER'] = df.apply(lambda x: jiwer.cer(x['input_string'], x['translated_string']), axis=1)\n",
    "    else:\n",
    "        df['translated_WER'] = 1.0\n",
    "        df['translated_CER'] = 1.0\n",
    "    \n",
    "    # ----- Step 6 : Remove and rearrange columns ----- #\n",
    "    df = df.drop(columns=['trans_CER', 'trans_WER', 'target_CER_sum'])\n",
    "\n",
    "    # Check if speaker_id is in the columns\n",
    "    if 'speaker_id' in df.columns:\n",
    "        new_arangment = ['speaker_id', 'score',\n",
    "                        'input_string', 'PER', 'WER',\n",
    "                        'translated_string','translated_CER', 'translated_WER',\n",
    "                        'length_deviation_words',\t'audio_name',\t'audio_path']\n",
    "        df = df[new_arangment]\n",
    "        \n",
    "    \n",
    "    \n",
    "    # --- Extract and modify the model name for plotting --- # \n",
    "    model_name = file.split('__')[0] \n",
    "    if model_name.startswith('nb'):\n",
    "        mn_split = model_name.split('-whisper')\n",
    "        if not len(mn_split) == 2:\n",
    "            print(f'Error: model name split failed. Len: {len(mn_split)}. Split: {mn_split}')\n",
    "        else:\n",
    "            model_name = 'NNL' + mn_split[1]\n",
    "    else:\n",
    "        model_name = model_name.capitalize()\n",
    "        \n",
    "    df['model_name'] = model_name\n",
    "    \n",
    "    # ----- Step 7 : Save the data ----- #\n",
    "    dir = '../Concat_results/corrected_data'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "    df.to_csv(f'{dir}/{file}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
