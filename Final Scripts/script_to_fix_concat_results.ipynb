{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style=\"color:#ADF88B\">Fix Concatenation Results</span></b>\n",
    "\n",
    "Script to fix the concatenated result data frame. I recreate excatly how the audio files are concatenated, and exstracting the target words, target PER, target WER and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys      \n",
    "script_directory = '../'\n",
    "sys.path.append(script_directory)\n",
    "import self_made_functions as smf\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assessment, _ = smf.get_correct_df()\n",
    "df_assessment['id'] = df_assessment['File name'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "# Test 1 :  Grouping by score. Sorted by speaker.\n",
    "df_test_1 = df_assessment.sort_values(by=['id'], ascending=False) # Sorted by ID\n",
    "df_test_1 = df_test_1.reset_index(drop=True)\n",
    "df_test_1 = df_test_1.groupby('Score')# Grouped by score\n",
    "df_test_1_name = 'scores_id_sorted'\n",
    "\n",
    "# Test 2 :  Grouping by score. Random speakers.\n",
    "df_test_2 = df_assessment.sample(frac=1).reset_index(drop=True)\n",
    "df_test_2 = df_test_2.groupby('Score')\n",
    "df_test_2_name = 'scores_id_mixed'\n",
    "\n",
    "# Test 3 :  Grouping by speaker. No sorting.\n",
    "df_test_3 = df_assessment.groupby('id')# Grouped by speaker\n",
    "df_test_3_name = 'group_id_sorted_score'\n",
    "\n",
    "# Test 4 :  No group. Everything in random order.\n",
    "df_test_4 = df_assessment.sample(frac=1).reset_index(drop=True)\n",
    "df_test_4_name = 'no_group_mixed'\n",
    "\n",
    "# --------- Store Information ------------ #\n",
    "halo_df = pd.DataFrame(columns=['PER', \n",
    "                                'WER', \n",
    "                                'input_words_list', \n",
    "                                'audio_name', \n",
    "                                'test_name',\n",
    "                                'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3606217/3318079430.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  halo_df = pd.concat([halo_df, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : Grouping by score. Sorted by speaker.\n",
    "for idx, score_group in df_test_1:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, wer, input_lst, audio_name = concat_audio(score_group, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_1_name,\n",
    "                'test' : 1} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 : Grouping by score. Random speakers.\n",
    "for idx, score_group in df_test_2:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(score_group, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_2_name,\n",
    "                'test' : 2} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 : Grouping by speaker. No sorting.\n",
    "for idx, person in df_test_3:\n",
    "    for i in range(0, len(score_group)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        speaker_id = person.iloc[0]['id']\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(score_group, s, e, name=f'{speaker_id}_')\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_3_name,\n",
    "                'test' : 3} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4 : No group. Everything in random order.\n",
    "for i in range(0, len(df_test_4)//10,10):\n",
    "        s, e = i, i + 10 # get start and end index\n",
    "        target_per, target_wer, input_lst, audio_name = concat_audio(df_test_4, s, e)\n",
    "        new_df = {'PER' : target_per, \n",
    "                'WER' : target_wer, \n",
    "                'input_words_list' : [input_lst], \n",
    "                'audio_name' : audio_name,\n",
    "                'test_name' : df_test_4_name,\n",
    "                'test' : 4} \n",
    "        new_df = pd.DataFrame(new_df)\n",
    "        halo_df = pd.concat([halo_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the current information CSV files\n",
    "\n",
    "1) ~~Load the transcribed CSV~~\n",
    "2) ~~Check that all the audio_names and input_words_list match~~\n",
    "3) ~~Add the correct information to the CSV~~\n",
    "4) Strip the transcriptions properly\n",
    "5) ~~Fix update CER and WER~~\n",
    "6) ~~Create a new file with the correct information~~\n",
    "7) Check no transcriptions has NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 3 values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_group_id_sorted_score_v1.csv.\n",
      "Error: 1 values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_no_group_mixed_v1.csv.\n",
      "Error: 2 values in the translated_string column for file nb-whisper-base-verbatim__concatenated_audio_information_scores_id_sorted_v1.csv.\n",
      "Error: 1 values in the translated_string column for file nb-whisper-medium__concatenated_audio_information_scores_id_mixed_v1.csv.\n",
      "Error: 1 values in the translated_string column for file nb-whisper-medium-verbatim__concatenated_audio_information_scores_id_mixed_v1.csv.\n"
     ]
    }
   ],
   "source": [
    "file_lst = os.listdir('../3x10_Concatenation_information')\n",
    "\n",
    "for file in file_lst:\n",
    "    # print(f'Working on file: {file}')\n",
    "    # ----- Step 1 : Load the data ----- #\n",
    "    df = pd.read_csv(f'../3x10_Concatenation_information/{file}')\n",
    "    get_test = file.split('_information_')[1].split('_v1')[0]\n",
    "    df = df.rename(columns={'target_CER': 'PER', 'target_WER': 'WER'}) # Renaming columns\n",
    "    \n",
    "    # Get the split data frame from halo_df\n",
    "    same_df_split = halo_df[(halo_df['test_name'] == get_test) & \n",
    "                            (halo_df['audio_name'].isin(df['audio_name']))]\n",
    "    \n",
    "    # Rename columns in same_df_split to avoid conflicts\n",
    "    same_df_split = same_df_split.rename(columns={'PER': 'PER_temp', 'WER': 'WER_temp'})\n",
    "        \n",
    "    # Verify there are no conflicting column names before merging\n",
    "    if 'WER' in same_df_split.columns or 'PER' in same_df_split.columns:\n",
    "        print(f'Error: Conflicting column names found in same_df_split for file {file}')\n",
    "        break\n",
    "    \n",
    "    # ----- Step 2 & 3 : Merge the data ----- #\n",
    "    # same_df_split = halo_df[(halo_df['test_name'] == get_test) & \n",
    "    #                     (halo_df['audio_name'].isin(df['audio_name']))]\n",
    "    if not len(same_df_split) == len(df):\n",
    "        print(f'Error: Length of split data frames does not match for file {file}.\\n{len(same_df_split)} vs {len(df)}')\n",
    "    \n",
    "    # Merging df with same_df_split on the 'audio_name' column\n",
    "    merged_df = df.merge(same_df_split[['audio_name', 'PER_temp', 'WER_temp']], on='audio_name', how='left')\n",
    "\n",
    "    # Updating the 'PER' column in df with the values from the merged DataFrame\n",
    "    df['PER'] = merged_df['PER_temp']\n",
    "    df['WER'] = merged_df['WER_temp']\n",
    "    \n",
    "    # Check for nans to ensure smooth merge\n",
    "    if df['PER'].isnull().values.any():\n",
    "        print(f'Error Critical: NaN values in the PER column for file {file}.')\n",
    "                \n",
    "    if df['WER'].isnull().values.any():\n",
    "        print(f'Error Critical: NaN values in the WER column for file {file}.')\n",
    "        \n",
    "    # ----- Step 4 : Strip the transcriptions ----- #\n",
    "    df['translated_string'] = df['translated_string'].apply(lambda x: x.strip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\") \n",
    "        if isinstance(x, str) else x)\n",
    "    \n",
    "    # ----- Step 5 : Calculate the CER & WER ----- #\n",
    "    nan = df['translated_string'].isna().sum() # Check for NaN values   \n",
    "    if nan > 0:\n",
    "        print(f'Error: {nan} values in the translated_string column for file {file}.')  \n",
    "\n",
    "    # Calculate WER, replacing with 1.0 if NaN\n",
    "    df['translated_WER'] = df.apply(lambda row: 1.0 if pd.isna(row['translated_string']) \n",
    "                                    else jiwer.wer(row['input_string'], row['translated_string']), axis=1)\n",
    "\n",
    "    # Calculate CER, replacing with 1.0 if NaN\n",
    "    df['translated_CER'] = df.apply(lambda row: 1.0 if pd.isna(row['translated_string']) \n",
    "                                    else jiwer.cer(row['input_string'], row['translated_string']), axis=1)\n",
    "    \n",
    "    # ----- Step 6 : Remove and rearrange columns ----- #\n",
    "    df = df.drop(columns=['trans_CER', 'trans_WER', 'target_CER_sum'])\n",
    "\n",
    "    # Check if speaker_id is in the columns\n",
    "    if 'speaker_id' in df.columns:\n",
    "        new_arrangement = ['speaker_id', 'score',\n",
    "                        'input_string', 'PER', 'WER',\n",
    "                        'translated_string','translated_CER', 'translated_WER',\n",
    "                        'length_deviation_words',\t'audio_name',\t'audio_path']\n",
    "        df = df[new_arrangement]\n",
    "    else:\n",
    "        new_arrangement = ['score',\n",
    "                        'input_string', 'PER', 'WER',\n",
    "                        'translated_string','translated_CER', 'translated_WER',\n",
    "                        'length_deviation_words', \"unique_id's\", \"speaker_id's\",\n",
    "                        'audio_name',\t'audio_path']\n",
    "        df = df[new_arrangement]\n",
    "    \n",
    "    # --- Extract and modify the model name for plotting --- # \n",
    "    model_name = file.split('__')[0] \n",
    "    if model_name.startswith('nb'):\n",
    "        mn_split = model_name.split('-whisper')\n",
    "        if not len(mn_split) == 2:\n",
    "            print(f'Error: model name split failed. Len: {len(mn_split)}. Split: {mn_split}')\n",
    "        else:\n",
    "            model_name = 'NNL' + mn_split[1]\n",
    "    else:\n",
    "        model_name = model_name.capitalize()\n",
    "        \n",
    "    df['model_name'] = model_name\n",
    "    \n",
    "    # ----- Step 7 : Save the data ----- #\n",
    "    dir = '../Concat_results/corrected_data'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    # # Example condition on a DataFrame df\n",
    "    # condition = (df['length_deviation_words'] != 0) & (df['translated_WER'] == 1.0)\n",
    "\n",
    "    # # Applying the condition to filter rows\n",
    "    # filtered_df = df[condition]\n",
    "\n",
    "    # # Check if any rows meet the condition\n",
    "    # if filtered_df.shape[0] > 0:\n",
    "    #     # Iterate over the rows if needed\n",
    "    #     for index, row in filtered_df.iterrows():\n",
    "    #         print(f\"Error: Length deviation is not 0 but WER is 1.0 for file.\")\n",
    "    #         print(row['length_deviation_words'])\n",
    "    # else:\n",
    "    #     print(\"No errors found.\")\n",
    "\n",
    "    # # Example to handle Series truth value ambiguity\n",
    "    # import numpy as np\n",
    "    # if np.any(condition):\n",
    "    #     print(\"At least one row meets the condition.\")\n",
    "    # else:\n",
    "    #     print(\"No rows meet the condition.\")\n",
    "        \n",
    "    df.to_csv(f'{dir}/{file}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
