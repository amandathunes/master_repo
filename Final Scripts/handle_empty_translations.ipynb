{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style=\"color:#FF9671\"> Remove Emty Transcriptions from the Transcribed Data Frame </span></b>\n",
    "\n",
    "For some reason, some of the empty transcriptions sneak into the transcribed data frame. This script fixes this.\n",
    "\n",
    "Look for rows in the transcription with <b><span style=\"color:#FF6F91\">NaN</span></b> values and rows in the assessment that are not in the transcription.\n",
    "\n",
    "After <b><span style=\"color:#FF6F91\">removing</span></b> the NaN value rows, we are left with <b><span style=\"color:#FF6F91\">comparing</span></b> the missing data from the assessment to the transcription.\n",
    "\n",
    "All <b><span style=\"color:#FF6F91\">missing rows</span></b> are assumed to be <b><span style=\"color:#FF6F91\">empty transcriptions</span></b> and are given <b><span style=\"color:#FF6F91\">CER = 1.0</span></b>. \n",
    "\n",
    "A new empty transcription file is created and saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style=\"color:#FF9671\">  Library Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this scripts task is to go throng all the transcribed files. \n",
    "# It checks if there are any missing values in the transcribed files, that is not in the empty transcriptions file.\n",
    "# It also compar the length to teh assessment files, and assume theses row are all files the model could not transcribe\n",
    "# They are therefor deemed as empty transcriptions, and given CER = 1.0\n",
    "import sys      \n",
    "\n",
    "script_directory = '../'\n",
    "sys.path.append(script_directory)\n",
    "\n",
    "import self_made_functions as smf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <b><span style=\"color:#FF9671\">  Data Initialization</b>\n",
    "\n",
    "Get the transcribed files, the assessment df, and Initiate the empty list to store the fixed transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transcribed files to look through\n",
    "path_transcriptions = '../Transcriptions'\n",
    "lst = os.listdir(path_transcriptions)\n",
    "lst = [file for file in lst if file.startswith('tran') and file.endswith('.csv')]\n",
    "\n",
    "# Compar with original assessment\n",
    "df_assessment, _ = smf.get_correct_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <b><span style=\"color:#FF9671\">  Remove NaN values </span></b>\n",
    "Iterate through all the transcriptions and find missing values. Remove these from the transcribed data frame, and save them accordantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n",
      "No NaN\n"
     ]
    }
   ],
   "source": [
    "for file in lst:\n",
    "    df_csv = pd.read_csv(os.path.join(path_transcriptions, file))\n",
    "    nan_df = df_csv[df_csv['Transcribed'].isna()]\n",
    "    \n",
    "    if not nan_df.empty:\n",
    "        print(f'NaN in {file}')\n",
    "        df_csv = df_csv.dropna()\n",
    "        df_csv.to_csv(os.path.join(path_transcriptions, file), index=False)\n",
    "    else:\n",
    "        print(f'No NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <b><span style=\"color:#FF9671\">  Creating empty transcription file </span></b>\n",
    "Now, there is non nan values in the transcribed data frame. Meaning all missing rows in the assessment data frame are empty transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1518214/778969144.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  empty_transcriptions = pd.concat([empty_transcriptions, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the empty transcriptions data frame\n",
    "empty_transcriptions = pd.DataFrame(columns=[\"file_name\",\n",
    "                                \"CER\",  # Character Error Rate (CER)\n",
    "                                \"target_word\", \n",
    "                                \"global_score\",\n",
    "                                'model_name', 'version'])\n",
    "\n",
    "# Iterate throng all the transcriptions and find the missing values\n",
    "for file in lst:\n",
    "    df_csv = pd.read_csv(os.path.join(path_transcriptions, file))\n",
    "    model = file.split('_')[1]\n",
    "    version = file.split('_')[2].split('.')[0]\n",
    "    \n",
    "    # Find the missing rows from the assessment\n",
    "    missing_rows = df_assessment[~df_assessment['File name'].isin(df_csv['File name'])]\n",
    "    \n",
    "    # Add the missing rows to the empty transcriptions\n",
    "    for i, row in missing_rows.iterrows():\n",
    "        new_row = {\"file_name\": row['File name'],\n",
    "                    \"CER\": 1.0,  # Character Error Rate (CER)\n",
    "                    \"target_word\": row['Word'], \n",
    "                    \"global_score\": row['Score'],\n",
    "                    'model_name': model,\n",
    "                    'version': version}\n",
    "        new_row = pd.DataFrame(new_row, index=[0])\n",
    "        empty_transcriptions = pd.concat([empty_transcriptions, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <b><span style=\"color:#FF6F91\">  Check if it was correctly saved in the empty data frame</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 9322 9322 nb-whisper-base-verbatim v1\n",
      "True 9322 9322 nb-whisper-medium-verbatim v1\n",
      "True 9322 9322 tiny v1\n",
      "True 9322 9322 base v1\n",
      "True 9322 9322 medium v1\n",
      "True 9322 9322 nb-whisper-base v1\n",
      "True 9322 9322 nb-whisper-medium v1\n",
      "True 9322 9322 nb-whisper-base-verbatim v2\n",
      "True 9322 9322 nb-whisper-medium-verbatim v2\n",
      "True 9322 9322 nb-whisper-tiny-verbatim v1\n",
      "True 9322 9322 nb-whisper-tiny-verbatim v2\n",
      "True 9322 9322 nb-whisper-tiny v1\n"
     ]
    }
   ],
   "source": [
    "for file in lst:\n",
    "    df_csv = pd.read_csv(os.path.join(path_transcriptions, file))\n",
    "    model = file.split('_')[1]\n",
    "    version = file.split('_')[2].split('.')[0]\n",
    "    check = empty_transcriptions[(empty_transcriptions['version']==version) & (empty_transcriptions['model_name']==model)]\n",
    "\n",
    "    print(len(check) + len(df_csv)==len(df_assessment), len(check) + len(df_csv), len(df_assessment), model, version)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <b><span style=\"color:#FF9671\">  Save the empty data frame </span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in empty_transcriptions['version'].unique():\n",
    "    df_to_save = empty_transcriptions[empty_transcriptions['version']==version]\n",
    "    df_to_save = df_to_save.drop(columns=['version'])\n",
    "    df_to_save.to_csv(f'./Transcriptions/empty_transcriptions_{version}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_amanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
